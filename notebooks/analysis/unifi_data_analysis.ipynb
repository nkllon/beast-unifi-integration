{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniFi Data Analysis\n",
    "\n",
    "Fetch data from UniFi Site Manager API and create DataFrames for analysis.\n",
    "\n",
    "**üí° Debugging Tip:** For better visualization viewing, run the \"Launch Notebook in Browser\" cell at the end to open this notebook in a browser with full automation hooks!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install requests pandas python-dotenv --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API key loaded from ~/.env\n",
      "‚úì Ready to fetch data from UniFi Site Manager API\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from ~/.env\n",
    "env_path = Path.home() / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Get API key from environment\n",
    "api_key = os.getenv('UNIFI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"UNIFI_API_KEY not found in ~/.env file. Please add it.\")\n",
    "\n",
    "print(f\"‚úì API key loaded from ~/.env\")\n",
    "print(f\"‚úì Ready to fetch data from UniFi Site Manager API\")\n",
    "\n",
    "# Create API session\n",
    "api_session = requests.Session()\n",
    "api_session.headers.update({\n",
    "    'X-API-Key': api_key,\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data from UniFi API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from UniFi Site Manager API...\n",
      "\n",
      "‚úì hosts        - hosts                - 2 items\n",
      "‚úì sites        - sites                - 2 items\n",
      "‚úì devices      - devices              - 1 items\n",
      "‚úó networks     - Error 404\n",
      "‚úó clients      - Error 404\n",
      "‚úó events       - Error 404\n",
      "‚úó system       - Error 404\n",
      "\n",
      "‚úì Fetched data from 3 endpoints\n"
     ]
    }
   ],
   "source": [
    "# UniFi Site Manager API endpoints\n",
    "endpoints = {\n",
    "    'hosts': 'https://api.ui.com/v1/hosts',\n",
    "    'sites': 'https://api.ui.com/v1/sites',\n",
    "    'devices': 'https://api.ui.com/v1/devices',\n",
    "    'networks': 'https://api.ui.com/v1/networks',\n",
    "    'clients': 'https://api.ui.com/v1/clients',\n",
    "    'events': 'https://api.ui.com/v1/events',\n",
    "    'system': 'https://api.ui.com/v1/system',\n",
    "}\n",
    "\n",
    "print(\"Fetching data from UniFi Site Manager API...\\n\")\n",
    "api_data = {}\n",
    "\n",
    "for name, endpoint in endpoints.items():\n",
    "    try:\n",
    "        response = api_session.get(endpoint, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            api_data[name] = data\n",
    "            if isinstance(data, dict) and 'data' in data:\n",
    "                count = len(data['data']) if isinstance(data['data'], list) else 'N/A'\n",
    "                print(f\"‚úì {name:12s} - {endpoint.split('/')[-1]:20s} - {count} items\")\n",
    "            else:\n",
    "                print(f\"‚úì {name:12s} - {endpoint.split('/')[-1]:20s} - data retrieved\")\n",
    "        elif response.status_code == 401:\n",
    "            print(f\"‚úó {name:12s} - Unauthorized (check API key)\")\n",
    "        elif response.status_code == 403:\n",
    "            print(f\"‚úó {name:12s} - Forbidden (insufficient permissions)\")\n",
    "        else:\n",
    "            print(f\"‚úó {name:12s} - Error {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚úó {name:12s} - Connection error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úì Fetched data from {len(api_data)} endpoints\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrames...\n",
      "\n",
      "‚úì hosts        -    2 rows √ó 151 columns\n",
      "‚úì sites        -    2 rows √ó  43 columns\n",
      "‚úì devices      -    1 rows √ó   3 columns\n",
      "\n",
      "‚úì Created 3 DataFrame(s)\n",
      "\n",
      "Available DataFrames: ['hosts', 'sites', 'devices']\n"
     ]
    }
   ],
   "source": [
    "def create_dataframe(data, name=\"data\"):\n",
    "    \"\"\"\n",
    "    Convert API response data into a pandas DataFrame using json_normalize\n",
    "    for proper handling of nested JSON structures\n",
    "    \n",
    "    Args:\n",
    "        data: API response data (dict with 'data' key, or list, or dict)\n",
    "        name: Name for the DataFrame (for display purposes)\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        if 'data' in data:\n",
    "            items = data['data']\n",
    "        else:\n",
    "            items = [data]\n",
    "    elif isinstance(data, list):\n",
    "        items = data\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    if not items or len(items) == 0:\n",
    "        return None\n",
    "    \n",
    "    if isinstance(items, list) and len(items) > 0:\n",
    "        try:\n",
    "            # Use json_normalize for nested structures\n",
    "            df = pd.json_normalize(items)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error creating DataFrame for {name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Fallback to regular DataFrame\n",
    "            try:\n",
    "                df = pd.DataFrame(items)\n",
    "                return df\n",
    "            except Exception as e2:\n",
    "                print(f\"‚úó Fallback also failed for {name}: {e2}\")\n",
    "                return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create DataFrames from API data\n",
    "print(\"Creating DataFrames...\\n\")\n",
    "dataframes = {}\n",
    "\n",
    "for name, data in api_data.items():\n",
    "    df = create_dataframe(data, name)\n",
    "    if df is not None:\n",
    "        dataframes[name] = df\n",
    "        print(f\"‚úì {name:12s} - {df.shape[0]:4d} rows √ó {df.shape[1]:3d} columns\")\n",
    "\n",
    "print(f\"\\n‚úì Created {len(dataframes)} DataFrame(s)\")\n",
    "print(f\"\\nAvailable DataFrames: {list(dataframes.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display DataFrame Summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATAFRAME: HOSTS\n",
      "============================================================\n",
      "Shape: 2 rows √ó 151 columns\n",
      "\n",
      "Columns (151):\n",
      "id, hardwareId, type, ipAddress, owner, isBlocked, registrationTime, lastConnectionStateChange, latestBackupTime, userData.permissions.network.management, userData.status, reportedState.controller_uuid, reportedState.firmware_version, reportedState.hardware_id, reportedState.host_type\n",
      "... and 136 more\n",
      "\n",
      "First few rows:\n",
      "                                                  id  \\\n",
      "0               67be1762-80ee-46dd-a25f-dd69d18da8c6   \n",
      "1  74ACB93D0FFB0000000004AEDD420000000004E4063400...   \n",
      "\n",
      "                             hardwareId            type     ipAddress  owner  \\\n",
      "0  0ad4313b-ebc9-40e9-b5fd-f020e99c15e9  network-server  73.78.113.14   True   \n",
      "1  5883cf3e-f791-5bb7-815f-fb78f4fde4d0         console  73.78.113.14   True   \n",
      "\n",
      "   isBlocked      registrationTime lastConnectionStateChange  \\\n",
      "0      False  2024-09-20T00:26:41Z      2025-09-08T22:14:16Z   \n",
      "1      False                            2025-10-23T22:31:50Z   \n",
      "\n",
      "       latestBackupTime userData.permissions.network.management  ...  \\\n",
      "0                                                       [admin]  ...   \n",
      "1  2025-10-31T09:31:45Z                                 [admin]  ...   \n",
      "\n",
      "                reportedState.uidb.guid                 reportedState.uidb.id  \\\n",
      "0                                   NaN                                   NaN   \n",
      "1  59a52bba-e33b-4739-a82d-7e875c8ded0e  142cd194-8164-46a1-ba48-bef078757393   \n",
      "\n",
      "   reportedState.uidb.images.default  \\\n",
      "0                                NaN   \n",
      "1   015d558b57f631225c3ba6a73660d4df   \n",
      "\n",
      "  reportedState.uidb.images.mobile-connection  \\\n",
      "0                                         NaN   \n",
      "1            e35a45247f382d2f952ffb1d7f3450f2   \n",
      "\n",
      "   reportedState.uidb.images.mobile-internet-connected  \\\n",
      "0                                                NaN     \n",
      "1                   8c5965a0983cadd2eec4679def0aa016     \n",
      "\n",
      "  reportedState.uidb.images.mobile-no-internet  \\\n",
      "0                                          NaN   \n",
      "1             4f71689cbabedbcc27b49edce2b9b637   \n",
      "\n",
      "   reportedState.uidb.images.nopadding reportedState.uidb.images.topology  \\\n",
      "0                                  NaN                                NaN   \n",
      "1     717d100bc54c02f91dfdb70555e14f02   74fa25dd073f2f833e72acd2436d2ec0   \n",
      "\n",
      "   reportedState.unadoptedUnifiOSDevices  \\\n",
      "0                                    NaN   \n",
      "1                                     []   \n",
      "\n",
      "                                  reportedState.wans  \n",
      "0                                                NaN  \n",
      "1  [{'enabled': True, 'interface': 'eth4', 'ipv4'...  \n",
      "\n",
      "[2 rows x 151 columns]\n",
      "\n",
      "============================================================\n",
      "DATAFRAME: SITES\n",
      "============================================================\n",
      "Shape: 2 rows √ó 43 columns\n",
      "\n",
      "Columns (43):\n",
      "siteId, hostId, permission, isOwner, meta.desc, meta.name, meta.timezone, statistics.counts.criticalNotification, statistics.counts.gatewayDevice, statistics.counts.guestClient, statistics.counts.lanConfiguration, statistics.counts.offlineDevice, statistics.counts.offlineGatewayDevice, statistics.counts.offlineWifiDevice, statistics.counts.offlineWiredDevice\n",
      "... and 28 more\n",
      "\n",
      "First few rows:\n",
      "                     siteId  \\\n",
      "0  66ecbfa4b5fe233342f37b24   \n",
      "1  5dcadb0441dd3c04f34db858   \n",
      "\n",
      "                                              hostId permission  isOwner  \\\n",
      "0               67be1762-80ee-46dd-a25f-dd69d18da8c6      admin     True   \n",
      "1  74ACB93D0FFB0000000004AEDD420000000004E4063400...      admin     True   \n",
      "\n",
      "  meta.desc meta.name   meta.timezone  statistics.counts.criticalNotification  \\\n",
      "0   Default   default  America/Denver                                       0   \n",
      "1   Default   default         Etc/UTC                                       0   \n",
      "\n",
      "   statistics.counts.gatewayDevice  statistics.counts.guestClient  ...  \\\n",
      "0                                0                              0  ...   \n",
      "1                                1                              0  ...   \n",
      "\n",
      "   statistics.percentages.txRetry  statistics.percentages.wanUptime  \\\n",
      "0                             NaN                               NaN   \n",
      "1                         9.11474                           99.3056   \n",
      "\n",
      "   statistics.wanMagic.available  statistics.wanMagic.enabled  \\\n",
      "0                            NaN                          NaN   \n",
      "1                          False                        False   \n",
      "\n",
      "   statistics.wanMagic.subscribed  statistics.wans.WAN.externalIp  \\\n",
      "0                             NaN                             NaN   \n",
      "1                           False                    73.14.204.31   \n",
      "\n",
      "   statistics.wans.WAN.ispInfo.name  statistics.wans.WAN.ispInfo.organization  \\\n",
      "0                               NaN                                       NaN   \n",
      "1                     Comcast Cable                              COMCAST-7922   \n",
      "\n",
      "                       statistics.wans.WAN.wanIssues  \\\n",
      "0                                                NaN   \n",
      "1  [{'highLatency': True, 'index': 5873514, 'late...   \n",
      "\n",
      "   statistics.wans.WAN.wanUptime  \n",
      "0                            NaN  \n",
      "1                        99.3056  \n",
      "\n",
      "[2 rows x 43 columns]\n",
      "\n",
      "============================================================\n",
      "DATAFRAME: DEVICES\n",
      "============================================================\n",
      "Shape: 1 rows √ó 3 columns\n",
      "\n",
      "Columns (3):\n",
      "hostId, devices, updatedAt\n",
      "\n",
      "First few rows:\n",
      "                                              hostId  \\\n",
      "0  74ACB93D0FFB0000000004AEDD420000000004E4063400...   \n",
      "\n",
      "                                             devices             updatedAt  \n",
      "0  [{'id': '74ACB93D0FFB', 'mac': '74ACB93D0FFB',...  2025-10-23T22:31:52Z  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary of each DataFrame\n",
    "for name, df in dataframes.items():\n",
    "    print(\"=\"*60)\n",
    "    print(f\"DATAFRAME: {name.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "    print(\", \".join(df.columns.tolist()[:15]))\n",
    "    if len(df.columns) > 15:\n",
    "        print(f\"... and {len(df.columns) - 15} more\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Individual DataFrames\n",
    "\n",
    "All DataFrames are stored in the `dataframes` dictionary. Access them like:\n",
    "\n",
    "- `dataframes['hosts']` - Hosts/sites information\n",
    "- `dataframes['devices']` - Network devices\n",
    "- `dataframes['clients']` - Connected clients\n",
    "- `dataframes['networks']` - Network configurations\n",
    "- `dataframes['events']` - System events\n",
    "- `dataframes['system']` - System information\n",
    "\n",
    "### Quick Access Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available DataFrames:\n",
      "  - hosts: 2 rows, 151 columns\n",
      "  - sites: 2 rows, 43 columns\n",
      "  - devices: 1 rows, 3 columns\n",
      "\n",
      "============================================================\n",
      "HOSTS/SITES\n",
      "============================================================\n",
      "                                                  id  \\\n",
      "0               67be1762-80ee-46dd-a25f-dd69d18da8c6   \n",
      "1  74ACB93D0FFB0000000004AEDD420000000004E4063400...   \n",
      "\n",
      "                             hardwareId            type     ipAddress  owner  \\\n",
      "0  0ad4313b-ebc9-40e9-b5fd-f020e99c15e9  network-server  73.78.113.14   True   \n",
      "1  5883cf3e-f791-5bb7-815f-fb78f4fde4d0         console  73.78.113.14   True   \n",
      "\n",
      "   isBlocked      registrationTime lastConnectionStateChange  \\\n",
      "0      False  2024-09-20T00:26:41Z      2025-09-08T22:14:16Z   \n",
      "1      False                            2025-10-23T22:31:50Z   \n",
      "\n",
      "       latestBackupTime userData.permissions.network.management  ...  \\\n",
      "0                                                       [admin]  ...   \n",
      "1  2025-10-31T09:31:45Z                                 [admin]  ...   \n",
      "\n",
      "                reportedState.uidb.guid                 reportedState.uidb.id  \\\n",
      "0                                   NaN                                   NaN   \n",
      "1  59a52bba-e33b-4739-a82d-7e875c8ded0e  142cd194-8164-46a1-ba48-bef078757393   \n",
      "\n",
      "   reportedState.uidb.images.default  \\\n",
      "0                                NaN   \n",
      "1   015d558b57f631225c3ba6a73660d4df   \n",
      "\n",
      "  reportedState.uidb.images.mobile-connection  \\\n",
      "0                                         NaN   \n",
      "1            e35a45247f382d2f952ffb1d7f3450f2   \n",
      "\n",
      "   reportedState.uidb.images.mobile-internet-connected  \\\n",
      "0                                                NaN     \n",
      "1                   8c5965a0983cadd2eec4679def0aa016     \n",
      "\n",
      "  reportedState.uidb.images.mobile-no-internet  \\\n",
      "0                                          NaN   \n",
      "1             4f71689cbabedbcc27b49edce2b9b637   \n",
      "\n",
      "   reportedState.uidb.images.nopadding reportedState.uidb.images.topology  \\\n",
      "0                                  NaN                                NaN   \n",
      "1     717d100bc54c02f91dfdb70555e14f02   74fa25dd073f2f833e72acd2436d2ec0   \n",
      "\n",
      "   reportedState.unadoptedUnifiOSDevices  \\\n",
      "0                                    NaN   \n",
      "1                                     []   \n",
      "\n",
      "                                  reportedState.wans  \n",
      "0                                                NaN  \n",
      "1  [{'enabled': True, 'interface': 'eth4', 'ipv4'...  \n",
      "\n",
      "[2 rows x 151 columns]\n",
      "\n",
      "============================================================\n",
      "DEVICES\n",
      "============================================================\n",
      "                                              hostId  \\\n",
      "0  74ACB93D0FFB0000000004AEDD420000000004E4063400...   \n",
      "\n",
      "                                             devices             updatedAt  \n",
      "0  [{'id': '74ACB93D0FFB', 'mac': '74ACB93D0FFB',...  2025-10-23T22:31:52Z  \n"
     ]
    }
   ],
   "source": [
    "# Quick access examples\n",
    "\n",
    "# Show available DataFrames\n",
    "print(\"Available DataFrames:\")\n",
    "for name in dataframes.keys():\n",
    "    df = dataframes[name]\n",
    "    print(f\"  - {name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Example: Display hosts/sites\n",
    "if 'hosts' in dataframes:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HOSTS/SITES\")\n",
    "    print(\"=\"*60)\n",
    "    print(dataframes['hosts'])\n",
    "elif 'sites' in dataframes:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SITES\")\n",
    "    print(\"=\"*60)\n",
    "    print(dataframes['sites'])\n",
    "\n",
    "# Example: Display devices\n",
    "if 'devices' in dataframes:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DEVICES\")\n",
    "    print(\"=\"*60)\n",
    "    # Show key columns if they exist\n",
    "    key_cols = ['name', 'model', 'ip', 'mac', 'version', 'status']\n",
    "    available_cols = [col for col in key_cols if col in dataframes['devices'].columns]\n",
    "    if available_cols:\n",
    "        print(dataframes['devices'][available_cols].head(10))\n",
    "    else:\n",
    "        print(dataframes['devices'].head(10))\n",
    "\n",
    "# Example: Display clients\n",
    "if 'clients' in dataframes:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLIENTS\")\n",
    "    print(\"=\"*60)\n",
    "    key_cols = ['hostname', 'ip', 'mac', 'essid', 'name']\n",
    "    available_cols = [col for col in key_cols if col in dataframes['clients'].columns]\n",
    "    if available_cols:\n",
    "        print(dataframes['clients'][available_cols].head(10))\n",
    "    else:\n",
    "        print(dataframes['clients'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export DataFrames to CSV\n",
    "\n",
    "Export any DataFrame to CSV for further analysis or sharing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting DataFrames to 'unifi_data_export' directory...\n",
      "\n",
      "‚úì Exported hosts        ‚Üí unifi_data_export/unifi_hosts_20251102_201520.csv\n",
      "‚úì Exported sites        ‚Üí unifi_data_export/unifi_sites_20251102_201520.csv\n",
      "‚úì Exported devices      ‚Üí unifi_data_export/unifi_devices_20251102_201520.csv\n",
      "\n",
      "‚úì Exported 3 DataFrames\n",
      "Files saved in: /Users/lou/Downloads/mid-linux-container-recipe.zurich-07-01-2025__patch2-09-24-2025_10-12-2025_0904.linux.x86-64/unifi_data_export\n"
     ]
    }
   ],
   "source": [
    "# Export all DataFrames to CSV\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"unifi_data_export\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"Exporting DataFrames to '{output_dir}' directory...\\n\")\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    filename = f\"{output_dir}/unifi_{name}_{timestamp}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úì Exported {name:12s} ‚Üí {filename}\")\n",
    "\n",
    "print(f\"\\n‚úì Exported {len(dataframes)} DataFrames\")\n",
    "print(f\"Files saved in: {os.path.abspath(output_dir)}\")\n",
    "\n",
    "# You can also export individual DataFrames:\n",
    "# dataframes['hosts'].to_csv('hosts.csv', index=False)\n",
    "# dataframes['devices'].to_csv('devices.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Examples\n",
    "\n",
    "Some common analysis operations you can perform on the DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Tip: Explore the DataFrames using pandas operations!\n",
      "   Examples:\n",
      "   - dataframes['devices'].describe()\n",
      "   - dataframes['clients'].groupby('essid').size()\n",
      "   - dataframes['devices'].filter(like='name')\n"
     ]
    }
   ],
   "source": [
    "# Analysis examples\n",
    "\n",
    "# 1. Count devices by model\n",
    "if 'devices' in dataframes:\n",
    "    if 'model' in dataframes['devices'].columns:\n",
    "        print(\"Device count by model:\")\n",
    "        print(dataframes['devices']['model'].value_counts())\n",
    "        print()\n",
    "\n",
    "# 2. Count clients by SSID\n",
    "if 'clients' in dataframes:\n",
    "    if 'essid' in dataframes['clients'].columns:\n",
    "        print(\"Clients by SSID:\")\n",
    "        print(dataframes['clients']['essid'].value_counts())\n",
    "        print()\n",
    "\n",
    "# 3. Show online vs offline devices\n",
    "if 'devices' in dataframes:\n",
    "    if 'state' in dataframes['devices'].columns:\n",
    "        print(\"Device status:\")\n",
    "        print(dataframes['devices']['state'].value_counts())\n",
    "        print()\n",
    "    elif 'status' in dataframes['devices'].columns:\n",
    "        print(\"Device status:\")\n",
    "        print(dataframes['devices']['status'].value_counts())\n",
    "        print()\n",
    "\n",
    "# 4. Network information\n",
    "if 'networks' in dataframes:\n",
    "    print(\"Networks:\")\n",
    "    key_cols = ['name', 'purpose', 'ip_subnet', 'enabled']\n",
    "    available_cols = [col for col in key_cols if col in dataframes['networks'].columns]\n",
    "    if available_cols:\n",
    "        print(dataframes['networks'][available_cols])\n",
    "    else:\n",
    "        print(dataframes['networks'].head())\n",
    "\n",
    "print(\"\\nüí° Tip: Explore the DataFrames using pandas operations!\")\n",
    "print(\"   Examples:\")\n",
    "print(\"   - dataframes['devices'].describe()\")\n",
    "print(\"   - dataframes['clients'].groupby('essid').size()\")\n",
    "print(\"   - dataframes['devices'].filter(like='name')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data for Schema Analysis\n",
    "\n",
    "Save the DataFrames so they can be loaded in the schema/database notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì DataFrames saved:\n",
      "   - unifi_data_cache/dataframes.pkl (all DataFrames as pickle)\n",
      "   - unifi_data_cache/parquet/ (individual files)\n",
      "\n",
      "üíæ To load in another notebook:\n",
      "   import pickle\n",
      "   with open('unifi_data_cache/dataframes.pkl', 'rb') as f:\n",
      "       dataframes = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrames for reuse in schema notebook\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"unifi_data_cache\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save DataFrames as pickle (preserves all data types and nested structures)\n",
    "dataframes_file = data_dir / \"dataframes.pkl\"\n",
    "with open(dataframes_file, 'wb') as f:\n",
    "    pickle.dump(dataframes, f)\n",
    "\n",
    "# Also save as parquet for each DataFrame (more portable, but may lose nested structures)\n",
    "parquet_dir = data_dir / \"parquet\"\n",
    "parquet_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    parquet_file = parquet_dir / f\"{name}.parquet\"\n",
    "    try:\n",
    "        # Try to save as parquet (won't work for columns with lists/dicts)\n",
    "        df.to_parquet(parquet_file, index=False)\n",
    "    except Exception as e:\n",
    "        # If parquet fails, save as pickle for this specific dataframe\n",
    "        pickle_file = parquet_dir / f\"{name}.pkl\"\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "print(f\"‚úì DataFrames saved:\")\n",
    "print(f\"   - {dataframes_file} (all DataFrames as pickle)\")\n",
    "print(f\"   - {parquet_dir}/ (individual files)\")\n",
    "print(f\"\\nüíæ To load in another notebook:\")\n",
    "print(f\"   import pickle\")\n",
    "print(f\"   with open('{dataframes_file}', 'rb') as f:\")\n",
    "print(f\"       dataframes = pickle.load(f)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Management APIs Discovery\n",
    "\n",
    "Searching for management/configuration APIs for DNS, WAN/HA, VPN, etc.\n",
    "\n",
    "**Note:** According to the [official Site Manager API documentation](https://developer.ui.com/site-manager-api/gettingstarted), the API is currently **read-only**. Future versions will include write operations and more granular configuration management.\n",
    "\n",
    "**Official Endpoints from Documentation:**\n",
    "- List Hosts\n",
    "- Get Host by ID\n",
    "- List Sites\n",
    "- List Devices\n",
    "- Get ISP Metrics (for monitoring internet providers)\n",
    "- Query ISP Metrics\n",
    "- **List SD-WAN Configs** (for WAN/HA configuration)\n",
    "- Get SD-WAN Config by ID\n",
    "- Get SD-WAN Config Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test official Site Manager API endpoints from documentation\n",
    "print(\"=\"*60)\n",
    "print(\"OFFICIAL SITE MANAGER API ENDPOINTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"Per documentation: https://developer.ui.com/site-manager-api/gettingstarted\\n\")\n",
    "\n",
    "# Get host and site IDs from existing data\n",
    "if 'hosts' in dataframes:\n",
    "    df_hosts = dataframes['hosts']\n",
    "    host_ids = df_hosts['id'].dropna().unique().tolist() if 'id' in df_hosts.columns else []\n",
    "    host_id = host_ids[0] if host_ids else None\n",
    "else:\n",
    "    host_id = None\n",
    "\n",
    "if 'sites' in dataframes:\n",
    "    df_sites = dataframes['sites']\n",
    "    site_ids = df_sites['siteId'].dropna().unique().tolist() if 'siteId' in df_sites.columns else []\n",
    "    site_id = site_ids[0] if site_ids else None\n",
    "else:\n",
    "    site_id = None\n",
    "\n",
    "# Official endpoints from documentation\n",
    "official_endpoints = {\n",
    "    'List Hosts': 'https://api.ui.com/v1/hosts',\n",
    "    'Get Host by ID': f'https://api.ui.com/v1/hosts/{host_id}' if host_id else None,\n",
    "    'List Sites': 'https://api.ui.com/v1/sites',\n",
    "    'List Devices': 'https://api.ui.com/v1/devices',\n",
    "    'Get ISP Metrics': 'https://api.ui.com/v1/isp-metrics',\n",
    "    'Query ISP Metrics': 'https://api.ui.com/v1/isp-metrics/query',\n",
    "    'List SD-WAN Configs': 'https://api.ui.com/v1/sd-wan-configs',\n",
    "}\n",
    "\n",
    "found_endpoints = {}\n",
    "\n",
    "print(\"Testing official endpoints:\\n\")\n",
    "for name, endpoint in official_endpoints.items():\n",
    "    if endpoint is None:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        resp = api_session.get(endpoint, timeout=10)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            found_endpoints[name] = endpoint\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                if 'data' in data:\n",
    "                    items = data['data']\n",
    "                    if isinstance(items, list):\n",
    "                        print(f\"‚úì {name:30s}: {len(items)} items\")\n",
    "                        if len(items) > 0 and isinstance(items[0], dict):\n",
    "                            print(f\"  ‚Üí Keys: {list(items[0].keys())[:8]}\")\n",
    "                    else:\n",
    "                        print(f\"‚úì {name:30s}: Config - {list(data.keys())[:5]}\")\n",
    "                else:\n",
    "                    print(f\"‚úì {name:30s}: Available - {list(data.keys())[:5]}\")\n",
    "            elif isinstance(data, list):\n",
    "                print(f\"‚úì {name:30s}: {len(data)} items\")\n",
    "        elif resp.status_code == 404:\n",
    "            print(f\"? {name:30s}: Not found (may need parameters)\")\n",
    "        elif resp.status_code == 400:\n",
    "            print(f\"? {name:30s}: Bad request (may need query parameters)\")\n",
    "        else:\n",
    "            print(f\"? {name:30s}: {resp.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {name:30s}: {str(e)[:40]}\")\n",
    "\n",
    "print(f\"\\n‚úì Found {len(found_endpoints)} accessible endpoints\")\n",
    "\n",
    "# If SD-WAN configs found, get details\n",
    "if 'List SD-WAN Configs' in found_endpoints:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SD-WAN CONFIGURATION (WAN/HA)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sdwan_resp = api_session.get('https://api.ui.com/v1/sd-wan-configs', timeout=15)\n",
    "    if sdwan_resp.status_code == 200:\n",
    "        sdwan_data = sdwan_resp.json()\n",
    "        if 'data' in sdwan_data and isinstance(sdwan_data['data'], list):\n",
    "            configs = sdwan_data['data']\n",
    "            if len(configs) > 0:\n",
    "                print(f\"\\nFound {len(configs)} SD-WAN configuration(s):\\n\")\n",
    "                for i, config in enumerate(configs):\n",
    "                    print(f\"SD-WAN Config {i+1}:\")\n",
    "                    for key, value in config.items():\n",
    "                        if isinstance(value, (dict, list)):\n",
    "                            print(f\"  {key}: {type(value).__name__}\")\n",
    "                            if isinstance(value, dict):\n",
    "                                print(f\"    ‚Üí {list(value.keys())[:10]}\")\n",
    "                            elif isinstance(value, list) and len(value) > 0:\n",
    "                                print(f\"    ‚Üí {len(value)} items\")\n",
    "                                if isinstance(value[0], dict):\n",
    "                                    print(f\"    ‚Üí Item keys: {list(value[0].keys())[:10]}\")\n",
    "                        else:\n",
    "                            print(f\"  {key}: {value}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"\\nNo SD-WAN configurations found.\")\n",
    "                print(\"SD-WAN is used for multi-WAN failover and site-to-site VPN.\")\n",
    "                print(\"If you have multiple internet providers configured, they would appear here.\")\n",
    "\n",
    "# Check ISP Metrics\n",
    "if 'Get ISP Metrics' in found_endpoints or 'Query ISP Metrics' in found_endpoints:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ISP METRICS (Internet Provider Monitoring)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"ISP Metrics endpoints are available for monitoring internet provider performance.\")\n",
    "    print(\"These may require query parameters - see API documentation for details.\")\n",
    "\n",
    "# Extract WAN/HA configuration from hosts data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WAN/HA CONFIGURATION IN HOSTS DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'hosts' in dataframes:\n",
    "    df_hosts = dataframes['hosts']\n",
    "    \n",
    "    # Check for WAN data in reportedState.wans\n",
    "    if 'reportedState.wans' in df_hosts.columns:\n",
    "        for idx, row in df_hosts.iterrows():\n",
    "            wans = row.get('reportedState.wans')\n",
    "            if isinstance(wans, list) and len(wans) > 0:\n",
    "                print(f\"\\nHost {idx+1}: {len(wans)} WAN interface(s)\")\n",
    "                for wan in wans:\n",
    "                    if isinstance(wan, dict):\n",
    "                        print(f\"  WAN: {wan.get('interface', 'unknown')}\")\n",
    "                        print(f\"    Type: {wan.get('type', 'unknown')}\")\n",
    "                        print(f\"    Enabled: {wan.get('enabled', 'N/A')}\")\n",
    "                        if 'ipv4' in wan and isinstance(wan['ipv4'], dict):\n",
    "                            print(f\"    IPv4: {wan['ipv4'].get('address', 'N/A')}\")\n",
    "                        if 'mac' in wan:\n",
    "                            print(f\"    MAC: {wan.get('mac', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MANAGEMENT API SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úì Official Site Manager API endpoints tested:\")\n",
    "print(\"   - SD-WAN Configs: For multi-WAN failover and site-to-site VPN\")\n",
    "print(\"   - ISP Metrics: For monitoring internet provider performance\")\n",
    "print(\"   - Note: API is currently READ-ONLY (per official documentation)\")\n",
    "print(\"\\n‚ö†Ô∏è  For write/configuration operations (DNS, VPN setup, routing rules):\")\n",
    "print(\"   Use the local UniFi Network Application API:\")\n",
    "print(\"   1. Access local controller at https://192.168.1.1:443\")\n",
    "print(\"   2. Create API token (Settings ‚Üí API Tokens, requires 2FA)\")\n",
    "print(\"   3. Query endpoints like:\")\n",
    "print(\"      - /proxy/network/api/s/{site}/rest/networkconf (networks)\")\n",
    "print(\"      - /proxy/network/api/s/{site}/rest/vpntunnel (VPN)\")\n",
    "print(\"      - /proxy/network/api/s/{site}/rest/dynamicdns (DNS)\")\n",
    "print(\"      - /proxy/network/api/s/{site}/rest/routing (routing/WAN)\")\n",
    "print(\"\\nüìö Full documentation: https://developer.ui.com/site-manager-api/gettingstarted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Network Application API (Write Operations)\n",
    "\n",
    "For configuration and write operations (DNS, VPN, routing, firewall rules), you need to access the local UniFi Network Application API using an API token.\n",
    "\n",
    "**Note:** UniFi OS requires 2FA, so username/password authentication won't work. You must create an API token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Local Network Application API for write operations\n",
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOCAL NETWORK APPLICATION API ACCESS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for API token\n",
    "local_token = os.getenv('UNIFI_LOCAL_TOKEN')\n",
    "\n",
    "if not local_token:\n",
    "    print(\"\\n‚ö†Ô∏è  UNIFI_LOCAL_TOKEN not found in ~/.env\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TO CREATE API TOKEN:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\"\"\n",
    "1. Log in to UniFi OS at https://192.168.1.1\n",
    "2. Go to Settings ‚Üí API Tokens (or User Settings ‚Üí API Tokens)\n",
    "3. Click \"Create New Token\"\n",
    "4. Give it a name (e.g., \"Notebook Access\")\n",
    "5. Set permissions (Network management, etc.)\n",
    "6. Copy the token immediately (shown only once)\n",
    "7. Add to ~/.env as: UNIFI_LOCAL_TOKEN=your_token_here\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"‚úì UNIFI_LOCAL_TOKEN found\")\n",
    "    \n",
    "    # Try to get local controller IP from hosts data\n",
    "    local_ips = ['192.168.1.1', '10.0.0.1', '172.16.0.1']\n",
    "    \n",
    "    # If we have hosts data, extract IPs from there\n",
    "    if 'hosts' in dataframes:\n",
    "        df_hosts = dataframes['hosts']\n",
    "        if 'ipAddress' in df_hosts.columns:\n",
    "            for ip in df_hosts['ipAddress'].dropna():\n",
    "                if isinstance(ip, str) and any(ip.startswith(prefix) for prefix in ['192.168.', '10.', '172.']):\n",
    "                    if ip.split('.')[0] not in [ip.split('.')[0] for ip in local_ips]:\n",
    "                        local_ips.insert(0, ip)\n",
    "    \n",
    "    print(f\"‚úì Testing connection to local controller...\\n\")\n",
    "    \n",
    "    connected = False\n",
    "    local_session = None\n",
    "    base_url = None\n",
    "    site_id = None\n",
    "    \n",
    "    for ip in local_ips:\n",
    "        test_urls = [\n",
    "            f'https://{ip}:443',\n",
    "            f'http://{ip}:8080',\n",
    "        ]\n",
    "        \n",
    "        for test_base in test_urls:\n",
    "            try:\n",
    "                session = requests.Session()\n",
    "                session.verify = False\n",
    "                session.headers.update({\n",
    "                    'Authorization': f'Bearer {local_token}',\n",
    "                    'Content-Type': 'application/json'\n",
    "                })\n",
    "                \n",
    "                # Test with sites endpoint\n",
    "                sites_url = f\"{test_base}/proxy/network/api/self/sites\"\n",
    "                resp = session.get(sites_url, timeout=10)\n",
    "                \n",
    "                if resp.status_code == 200:\n",
    "                    data = resp.json()\n",
    "                    if isinstance(data, dict) and 'data' in data:\n",
    "                        sites = data['data']\n",
    "                        print(f\"‚úì Connected to {test_base}\")\n",
    "                        print(f\"‚úì Found {len(sites)} site(s)\")\n",
    "                        \n",
    "                        if len(sites) > 0:\n",
    "                            site_id = sites[0].get('name', 'default')\n",
    "                            print(f\"‚úì Using site: {site_id}\")\n",
    "                            \n",
    "                            local_session = session\n",
    "                            base_url = test_base\n",
    "                            connected = True\n",
    "                            break\n",
    "            except requests.exceptions.SSLError:\n",
    "                # Try HTTP version\n",
    "                http_base = test_base.replace('https://', 'http://').replace(':443', ':8080')\n",
    "                try:\n",
    "                    session = requests.Session()\n",
    "                    session.headers.update({\n",
    "                        'Authorization': f'Bearer {local_token}',\n",
    "                        'Content-Type': 'application/json'\n",
    "                    })\n",
    "                    sites_url = f\"{http_base}/api/self/sites\"\n",
    "                    resp = session.get(sites_url, timeout=10)\n",
    "                    if resp.status_code == 200:\n",
    "                        data = resp.json()\n",
    "                        if isinstance(data, dict) and 'data' in data:\n",
    "                            sites = data['data']\n",
    "                            print(f\"‚úì Connected to {http_base}\")\n",
    "                            site_id = sites[0].get('name', 'default') if sites else 'default'\n",
    "                            local_session = session\n",
    "                            base_url = http_base\n",
    "                            connected = True\n",
    "                            break\n",
    "                except:\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if connected:\n",
    "            break\n",
    "    \n",
    "    if connected and local_session and site_id:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MANAGEMENT ENDPOINTS AVAILABLE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Test management endpoints\n",
    "        mgmt_endpoints = {\n",
    "            'Networks': f'/proxy/network/api/s/{site_id}/rest/networkconf',\n",
    "            'VPN Tunnels': f'/proxy/network/api/s/{site_id}/rest/vpntunnel',\n",
    "            'Dynamic DNS': f'/proxy/network/api/s/{site_id}/rest/dynamicdns',\n",
    "            'Routing': f'/proxy/network/api/s/{site_id}/rest/routing',\n",
    "            'Firewall Rules': f'/proxy/network/api/s/{site_id}/rest/firewallrule',\n",
    "            'Settings': f'/proxy/network/api/s/{site_id}/rest/setting',\n",
    "        }\n",
    "        \n",
    "        local_mgmt_data = {}\n",
    "        \n",
    "        for name, endpoint in mgmt_endpoints.items():\n",
    "            try:\n",
    "                # Adjust endpoint for HTTP if needed\n",
    "                if base_url.startswith('http://') and endpoint.startswith('/proxy'):\n",
    "                    endpoint = endpoint.replace('/proxy/network/api', '/api')\n",
    "                \n",
    "                url = f\"{base_url}{endpoint}\"\n",
    "                resp = local_session.get(url, timeout=10)\n",
    "                \n",
    "                if resp.status_code == 200:\n",
    "                    data = resp.json()\n",
    "                    if isinstance(data, dict) and 'data' in data:\n",
    "                        items = data['data']\n",
    "                        count = len(items) if isinstance(items, list) else 0\n",
    "                        print(f\"‚úì {name:20s}: {count} items (READ/WRITE)\")\n",
    "                        local_mgmt_data[name] = items\n",
    "                    else:\n",
    "                        print(f\"‚úì {name:20s}: Available (READ/WRITE)\")\n",
    "                        local_mgmt_data[name] = data\n",
    "                elif resp.status_code == 401:\n",
    "                    print(f\"‚úó {name:20s}: Unauthorized (check token permissions)\")\n",
    "                else:\n",
    "                    print(f\"? {name:20s}: {resp.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó {name:20s}: {str(e)[:40]}\")\n",
    "        \n",
    "        if local_mgmt_data:\n",
    "            print(f\"\\n‚úì Successfully accessed {len(local_mgmt_data)} management endpoint(s)\")\n",
    "            print(\"\\nüí° These endpoints support READ and WRITE operations!\")\n",
    "            print(\"   You can modify DNS, VPN, routing, firewall rules, etc.\")\n",
    "            print(\"\\n   Example: To update a network config:\")\n",
    "            print(f\"   PUT {base_url}/proxy/network/api/s/{site_id}/rest/networkconf/{{config_id}}\")\n",
    "            print(f\"   Body: {{'name': 'New Network Name', ...}}\")\n",
    "    else:\n",
    "        print(\"\\n‚úó Could not connect to local controller\")\n",
    "        print(\"   Check that:\")\n",
    "        print(\"   1. API token is correct\")\n",
    "        print(\"   2. Controller is accessible at 192.168.1.1 (or your network IP)\")\n",
    "        print(\"   3. Token has proper permissions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dive: Explore Site-Specific Data\n",
    "\n",
    "Many UniFi APIs require a site ID. Let's get site IDs from the hosts/sites data and explore site-specific endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 site(s) from 'hosts' DataFrame (column: id)\n",
      "\n",
      "‚úì Using site IDs: ['67be1762-80ee-46dd-a25f-dd69d18da8c6', '74ACB93D0FFB0000000004AEDD420000000004E40634000000005EBA61DE:1546669740']\n"
     ]
    }
   ],
   "source": [
    "# Extract site IDs from hosts or sites data\n",
    "site_ids = []\n",
    "\n",
    "# Try to get sites from hosts DataFrame\n",
    "if 'hosts' in dataframes:\n",
    "    df_hosts = dataframes['hosts']\n",
    "    # Common column names for site IDs\n",
    "    for col in ['site_id', 'id', 'siteId', 'host_id']:\n",
    "        if col in df_hosts.columns:\n",
    "            site_ids = df_hosts[col].dropna().unique().tolist()\n",
    "            print(f\"Found {len(site_ids)} site(s) from 'hosts' DataFrame (column: {col})\")\n",
    "            break\n",
    "\n",
    "# If no sites found, try sites DataFrame\n",
    "if not site_ids and 'sites' in dataframes:\n",
    "    df_sites = dataframes['sites']\n",
    "    for col in ['site_id', 'id', 'siteId']:\n",
    "        if col in df_sites.columns:\n",
    "            site_ids = df_sites[col].dropna().unique().tolist()\n",
    "            print(f\"Found {len(site_ids)} site(s) from 'sites' DataFrame (column: {col})\")\n",
    "            break\n",
    "\n",
    "# If still no sites, try to find any ID columns\n",
    "if not site_ids:\n",
    "    print(\"Searching for site IDs in all DataFrames...\")\n",
    "    for name, df in dataframes.items():\n",
    "        id_cols = [col for col in df.columns if 'id' in col.lower()]\n",
    "        if id_cols:\n",
    "            for col in id_cols:\n",
    "                unique_ids = df[col].dropna().unique()\n",
    "                if len(unique_ids) > 0:\n",
    "                    print(f\"  Found IDs in {name}.{col}: {unique_ids[:5]}\")\n",
    "                    if 'site' in col.lower() or len(unique_ids) <= 10:\n",
    "                        site_ids = unique_ids.tolist()\n",
    "                        break\n",
    "\n",
    "if site_ids:\n",
    "    print(f\"\\n‚úì Using site IDs: {site_ids[:5]}\")\n",
    "    if len(site_ids) > 5:\n",
    "        print(f\"  ... and {len(site_ids) - 5} more\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No site IDs found. Some site-specific endpoints may not work.\")\n",
    "    print(\"   Available DataFrame columns:\")\n",
    "    for name, df in list(dataframes.items())[:3]:\n",
    "        print(f\"   {name}: {list(df.columns)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Site-Specific Data\n",
    "\n",
    "If we have site IDs, let's try to fetch more detailed site-specific data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring site-specific endpoints for site: 67be1762-80ee-46dd-a25f-dd69d18da8c6\n",
      "\n",
      "‚úó site_devices         - Not found (endpoint may not exist)\n",
      "‚úó site_clients         - Not found (endpoint may not exist)\n",
      "‚úó site_wlans           - Not found (endpoint may not exist)\n",
      "‚úó site_networks        - Not found (endpoint may not exist)\n",
      "‚úó site_events          - Not found (endpoint may not exist)\n",
      "‚úó site_insights        - Not found (endpoint may not exist)\n",
      "\n",
      "Creating DataFrames from site-specific data...\n",
      "\n",
      "‚úì Total DataFrames available: 3\n"
     ]
    }
   ],
   "source": [
    "# Site-specific endpoints to try\n",
    "if site_ids:\n",
    "    site_id = site_ids[0]  # Use first site ID\n",
    "    print(f\"Exploring site-specific endpoints for site: {site_id}\\n\")\n",
    "    \n",
    "    site_endpoints = {\n",
    "        'site_devices': f'https://api.ui.com/v1/sites/{site_id}/devices',\n",
    "        'site_clients': f'https://api.ui.com/v1/sites/{site_id}/clients',\n",
    "        'site_wlans': f'https://api.ui.com/v1/sites/{site_id}/wlans',\n",
    "        'site_networks': f'https://api.ui.com/v1/sites/{site_id}/networks',\n",
    "        'site_events': f'https://api.ui.com/v1/sites/{site_id}/events',\n",
    "        'site_insights': f'https://api.ui.com/v1/sites/{site_id}/insights',\n",
    "    }\n",
    "    \n",
    "    site_data = {}\n",
    "    \n",
    "    for name, endpoint in site_endpoints.items():\n",
    "        try:\n",
    "            response = api_session.get(endpoint, timeout=15)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                site_data[name] = data\n",
    "                if isinstance(data, dict) and 'data' in data:\n",
    "                    count = len(data['data']) if isinstance(data['data'], list) else 'N/A'\n",
    "                    print(f\"‚úì {name:20s} - {count} items\")\n",
    "                else:\n",
    "                    print(f\"‚úì {name:20s} - data retrieved\")\n",
    "            elif response.status_code == 404:\n",
    "                print(f\"‚úó {name:20s} - Not found (endpoint may not exist)\")\n",
    "            elif response.status_code == 401:\n",
    "                print(f\"‚úó {name:20s} - Unauthorized\")\n",
    "            else:\n",
    "                print(f\"‚úó {name:20s} - Error {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó {name:20s} - {str(e)[:50]}\")\n",
    "    \n",
    "    # Create DataFrames from site-specific data\n",
    "    print(f\"\\nCreating DataFrames from site-specific data...\")\n",
    "    for name, data in site_data.items():\n",
    "        df = create_dataframe(data, name)\n",
    "        if df is not None:\n",
    "            dataframes[f'site_{name}'] = df\n",
    "            print(f\"‚úì Added site_{name} DataFrame ({df.shape[0]} rows)\")\n",
    "    \n",
    "    print(f\"\\n‚úì Total DataFrames available: {len(dataframes)}\")\n",
    "else:\n",
    "    print(\"Skipping site-specific endpoints (no site IDs found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis & Insights\n",
    "\n",
    "Let's perform deeper analysis on the available data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETAILED DATA ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üì± DEVICE ANALYSIS\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DETAILED DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Helper function to print value counts nicely\n",
    "def print_value_counts(df, col, label=\"\", max_items=20):\n",
    "    \"\"\"Print value counts in a formatted way\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return\n",
    "    counts = df[col].value_counts().head(max_items)\n",
    "    if label:\n",
    "        print(f\"\\n{label}:\")\n",
    "    for item, count in counts.items():\n",
    "        print(f\"  {item}: {count}\")\n",
    "\n",
    "# 1. Device Analysis\n",
    "if 'devices' in dataframes:\n",
    "    df = dataframes['devices']\n",
    "    print(\"üì± DEVICE ANALYSIS\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find relevant columns using vectorized operations\n",
    "    model_cols = [c for c in df.columns if 'model' in c.lower()]\n",
    "    status_cols = [c for c in df.columns if any(x in c.lower() for x in ['status', 'state'])]\n",
    "    version_cols = [c for c in df.columns if any(x in c.lower() for x in ['version', 'firmware'])]\n",
    "    \n",
    "    if model_cols:\n",
    "        print_value_counts(df, model_cols[0], \"Device Models\")\n",
    "    \n",
    "    if status_cols:\n",
    "        print_value_counts(df, status_cols[0], f\"Device Status (column: {status_cols[0]})\")\n",
    "    \n",
    "    if version_cols:\n",
    "        print_value_counts(df, version_cols[0], \"Firmware Versions\", max_items=10)\n",
    "    \n",
    "    print()\n",
    "\n",
    "# 2. Client Analysis\n",
    "if 'clients' in dataframes:\n",
    "    df = dataframes['clients']\n",
    "    print(\"üë• CLIENT ANALYSIS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\nTotal Clients: {len(df)}\")\n",
    "    \n",
    "    if 'essid' in df.columns:\n",
    "        print_value_counts(df, 'essid', \"Clients by SSID\")\n",
    "    \n",
    "    if 'ip' in df.columns:\n",
    "        valid_ips = df['ip'].dropna()\n",
    "        print(f\"\\nIP Addresses: {len(valid_ips)} clients with IPs\")\n",
    "        if len(valid_ips) > 0:\n",
    "            print(\"  Sample IPs:\", valid_ips.head(5).tolist())\n",
    "    \n",
    "    print()\n",
    "\n",
    "# 3. Network Analysis\n",
    "if 'networks' in dataframes:\n",
    "    df = dataframes['networks']\n",
    "    print(\"üåê NETWORK ANALYSIS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\nTotal Networks: {len(df)}\")\n",
    "    \n",
    "    if 'purpose' in df.columns:\n",
    "        print_value_counts(df, 'purpose', \"Networks by Purpose\")\n",
    "    \n",
    "    # Enabled networks using vectorized operation\n",
    "    enabled_cols = [c for c in df.columns if 'enabled' in c.lower()]\n",
    "    if enabled_cols and df[enabled_cols[0]].dtype == bool:\n",
    "        enabled_count = df[enabled_cols[0]].sum()\n",
    "        print(f\"\\nEnabled Networks: {enabled_count} / {len(df)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# 4. Events Analysis\n",
    "if 'events' in dataframes:\n",
    "    df = dataframes['events']\n",
    "    print(\"üìã EVENTS ANALYSIS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\\nTotal Events: {len(df)}\")\n",
    "    \n",
    "    type_cols = [c for c in df.columns if any(x in c.lower() for x in ['type', 'event'])]\n",
    "    if type_cols:\n",
    "        print_value_counts(df, type_cols[0], f\"Event Types (column: {type_cols[0]})\", max_items=10)\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Created 0 visualization(s)\n"
     ]
    }
   ],
   "source": [
    "# Install visualization libraries\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib seaborn --quiet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig_count = 0\n",
    "\n",
    "# 1. Device Model Distribution\n",
    "if 'devices' in dataframes and 'model' in dataframes['devices'].columns:\n",
    "    fig_count += 1\n",
    "    plt.figure(fig_count, figsize=(10, 6))\n",
    "    model_counts = dataframes['devices']['model'].value_counts()\n",
    "    model_counts.plot(kind='bar')\n",
    "    plt.title('Device Distribution by Model', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Model', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 2. Clients by SSID\n",
    "if 'clients' in dataframes and 'essid' in dataframes['clients'].columns:\n",
    "    fig_count += 1\n",
    "    plt.figure(fig_count, figsize=(10, 6))\n",
    "    ssid_counts = dataframes['clients']['essid'].value_counts()\n",
    "    ssid_counts.plot(kind='bar')\n",
    "    plt.title('Clients by SSID', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('SSID', fontsize=12)\n",
    "    plt.ylabel('Number of Clients', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Network Purpose Distribution\n",
    "if 'networks' in dataframes and 'purpose' in dataframes['networks'].columns:\n",
    "    fig_count += 1\n",
    "    plt.figure(fig_count, figsize=(8, 6))\n",
    "    purpose_counts = dataframes['networks']['purpose'].value_counts()\n",
    "    purpose_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Networks by Purpose', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. Device Status (if available)\n",
    "if 'devices' in dataframes:\n",
    "    status_cols = [col for col in dataframes['devices'].columns if 'status' in col.lower() or 'state' in col.lower()]\n",
    "    if status_cols:\n",
    "        fig_count += 1\n",
    "        plt.figure(fig_count, figsize=(8, 6))\n",
    "        status_counts = dataframes['devices'][status_cols[0]].value_counts()\n",
    "        status_counts.plot(kind='bar', color=['green', 'orange', 'red', 'gray'])\n",
    "        plt.title('Device Status Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Status', fontsize=12)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Created {fig_count} visualization(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Nested Data Structures\n",
    "\n",
    "Some API responses may contain nested dictionaries or lists. Let's flatten and explore these.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring nested data structures...\n",
      "\n",
      "  hosts: Found nested data in column 'userData.permissions.network.management'\n",
      "  sites: Found nested data in column 'statistics.internetIssues'\n",
      "  devices: Found nested data in column 'devices'\n",
      "    ‚Üí Can be expanded from 3 to ~24 columns\n",
      "\n",
      "============================================================\n",
      "EXAMPLE: Expanding nested device data\n",
      "============================================================\n",
      "\n",
      "Original columns: ['hostId', 'devices', 'updatedAt']\n",
      "\n",
      "Column 'devices' contains list with 1 items\n",
      "  First item keys: ['id', 'mac', 'name', 'model', 'shortname', 'ip', 'productLine', 'status', 'version', 'firmwareStatus']\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Flatten nested dictionary\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list) and len(v) > 0 and isinstance(v[0], dict):\n",
    "            # Handle list of dicts by taking first item\n",
    "            items.extend(flatten_dict(v[0], new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Check for nested structures in DataFrames\n",
    "print(\"Exploring nested data structures...\\n\")\n",
    "\n",
    "nested_dataframes = {}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # Check if any columns contain dict or list types\n",
    "    has_nested = False\n",
    "    for col in df.columns:\n",
    "        sample = df[col].dropna()\n",
    "        if len(sample) > 0:\n",
    "            first_val = sample.iloc[0]\n",
    "            if isinstance(first_val, dict) or (isinstance(first_val, list) and len(first_val) > 0):\n",
    "                has_nested = True\n",
    "                print(f\"  {name}: Found nested data in column '{col}'\")\n",
    "                break\n",
    "    \n",
    "    if has_nested:\n",
    "        # Try to flatten a sample row\n",
    "        try:\n",
    "            sample_row = df.iloc[0].to_dict()\n",
    "            flattened = flatten_dict(sample_row)\n",
    "            if len(flattened) > len(df.columns):\n",
    "                print(f\"    ‚Üí Can be expanded from {len(df.columns)} to ~{len(flattened)} columns\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Show example of expanding nested data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE: Expanding nested device data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'devices' in dataframes:\n",
    "    df_devices = dataframes['devices']\n",
    "    print(\"\\nOriginal columns:\", list(df_devices.columns)[:10])\n",
    "    \n",
    "    # Show which columns might have nested data\n",
    "    for col in df_devices.columns[:5]:\n",
    "        sample = df_devices[col].dropna()\n",
    "        if len(sample) > 0:\n",
    "            val = sample.iloc[0]\n",
    "            if isinstance(val, dict):\n",
    "                print(f\"\\nColumn '{col}' contains dict with keys: {list(val.keys())[:10]}\")\n",
    "            elif isinstance(val, list) and len(val) > 0:\n",
    "                print(f\"\\nColumn '{col}' contains list with {len(val)} items\")\n",
    "                if isinstance(val[0], dict):\n",
    "                    print(f\"  First item keys: {list(val[0].keys())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report\n",
    "\n",
    "Generate a comprehensive summary report of all findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UNIFI NETWORK SUMMARY REPORT\n",
      "============================================================\n",
      "Generated: 2025-11-02 20:15:22\n",
      "\n",
      "üìä DATA OVERVIEW\n",
      "------------------------------------------------------------\n",
      "Total DataFrames: 3\n",
      "Available DataFrames: devices, hosts, sites\n",
      "\n",
      "üìà DATA COUNTS\n",
      "------------------------------------------------------------\n",
      "  devices             :     1 rows √ó   3 columns\n",
      "  hosts               :     2 rows √ó 151 columns\n",
      "  sites               :     2 rows √ó  43 columns\n",
      "\n",
      "üîç KEY FINDINGS\n",
      "------------------------------------------------------------\n",
      "\n",
      "üì± Devices: 1 total\n",
      "\n",
      "============================================================\n",
      "\n",
      "üíæ All DataFrames are available in the 'dataframes' dictionary\n",
      "   Export data using: dataframes['name'].to_csv('filename.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"UNIFI NETWORK SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Overall statistics\n",
    "print(\"üìä DATA OVERVIEW\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total DataFrames: {len(dataframes)}\")\n",
    "print(f\"Available DataFrames: {', '.join(sorted(dataframes.keys()))}\")\n",
    "print()\n",
    "\n",
    "# Count items in each DataFrame\n",
    "print(\"üìà DATA COUNTS\")\n",
    "print(\"-\" * 60)\n",
    "for name in sorted(dataframes.keys()):\n",
    "    df = dataframes[name]\n",
    "    print(f\"  {name:20s}: {df.shape[0]:5d} rows √ó {df.shape[1]:3d} columns\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Key findings\n",
    "print(\"üîç KEY FINDINGS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Devices\n",
    "if 'devices' in dataframes:\n",
    "    df_devices = dataframes['devices']\n",
    "    print(f\"\\nüì± Devices: {len(df_devices)} total\")\n",
    "    if 'model' in df_devices.columns:\n",
    "        unique_models = df_devices['model'].nunique()\n",
    "        print(f\"   - Unique models: {unique_models}\")\n",
    "    if 'name' in df_devices.columns:\n",
    "        named_devices = df_devices['name'].notna().sum()\n",
    "        print(f\"   - Devices with names: {named_devices}\")\n",
    "\n",
    "# Clients\n",
    "if 'clients' in dataframes:\n",
    "    df_clients = dataframes['clients']\n",
    "    print(f\"\\nüë• Clients: {len(df_clients)} total\")\n",
    "    if 'essid' in df_clients.columns:\n",
    "        unique_ssids = df_clients['essid'].nunique()\n",
    "        print(f\"   - Unique SSIDs: {unique_ssids}\")\n",
    "    if 'ip' in df_clients.columns:\n",
    "        clients_with_ip = df_clients['ip'].notna().sum()\n",
    "        print(f\"   - Clients with IPs: {clients_with_ip}\")\n",
    "\n",
    "# Networks\n",
    "if 'networks' in dataframes:\n",
    "    df_networks = dataframes['networks']\n",
    "    print(f\"\\nüåê Networks: {len(df_networks)} total\")\n",
    "    if 'purpose' in df_networks.columns:\n",
    "        unique_purposes = df_networks['purpose'].nunique()\n",
    "        print(f\"   - Unique purposes: {unique_purposes}\")\n",
    "\n",
    "# Events\n",
    "if 'events' in dataframes:\n",
    "    df_events = dataframes['events']\n",
    "    print(f\"\\nüìã Events: {len(df_events)} total\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüíæ All DataFrames are available in the 'dataframes' dictionary\")\n",
    "print(\"   Export data using: dataframes['name'].to_csv('filename.csv', index=False)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying additional API endpoints...\n",
      "\n",
      "\n",
      "‚ö†Ô∏è  No additional endpoints found (this is normal - not all endpoints are available)\n"
     ]
    }
   ],
   "source": [
    "# Additional endpoints to explore\n",
    "additional_endpoints = [\n",
    "    'https://api.ui.com/v1/account',\n",
    "    'https://api.ui.com/v1/subscriptions',\n",
    "    'https://api.ui.com/v1/notifications',\n",
    "    'https://api.ui.com/v1/alerts',\n",
    "    'https://api.ui.com/v1/backups',\n",
    "    'https://api.ui.com/v1/settings',\n",
    "    'https://api.ui.com/v1/activity',\n",
    "    'https://api.ui.com/v1/statistics',\n",
    "    'https://api.ui.com/v1/traffic',\n",
    "    'https://api.ui.com/v1/health',\n",
    "]\n",
    "\n",
    "print(\"Trying additional API endpoints...\\n\")\n",
    "additional_data = {}\n",
    "\n",
    "for endpoint in additional_endpoints:\n",
    "    endpoint_name = endpoint.split('/')[-1]\n",
    "    try:\n",
    "        response = api_session.get(endpoint, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            additional_data[endpoint_name] = data\n",
    "            print(f\"‚úì {endpoint_name:20s} - Available\")\n",
    "        elif response.status_code == 404:\n",
    "            pass  # Silent - endpoint doesn't exist\n",
    "        else:\n",
    "            print(f\"‚úó {endpoint_name:20s} - Status {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        pass  # Silent - connection errors\n",
    "\n",
    "if additional_data:\n",
    "    print(f\"\\n‚úì Found {len(additional_data)} additional endpoints with data\")\n",
    "    print(f\"  Endpoints: {', '.join(additional_data.keys())}\")\n",
    "    \n",
    "    # Create DataFrames from additional data\n",
    "    for name, data in additional_data.items():\n",
    "        df = create_dataframe(data, name)\n",
    "        if df is not None:\n",
    "            dataframes[name] = df\n",
    "            print(f\"  ‚úì Added '{name}' DataFrame\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No additional endpoints found (this is normal - not all endpoints are available)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Based Analysis\n",
    "\n",
    "If your data has timestamps, let's analyze temporal patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for timestamp data...\n",
      "\n",
      "üìÖ hosts: Found timestamp columns - registrationTime, lastConnectionStateChange, latestBackupTime, reportedState.autoUpdate.includeApplications, reportedState.autoUpdate.preferencesPrompt.unifiOS.applications, reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.day, reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.frequency, reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.hour, reportedState.autoUpdate.preferencesPrompt.unifiOS.firmware, reportedState.autoUpdate.schedule.day, reportedState.autoUpdate.schedule.frequency, reportedState.autoUpdate.schedule.hour, reportedState.deviceStateLastChanged, reportedState.features.deviceList.partialUpdates, reportedState.features.infoApis.firmwareUpdate, reportedState.features.updates.applicationReleaseChannels, reportedState.features.updates.applicationSchedules, reportedState.firmwareUpdate.latestAvailableVersion, reportedState.timezone\n",
      "  ‚úì registrationTime: 1 valid timestamps\n",
      "    Range: 2024-09-20 00:26:41+00:00 to 2024-09-20 00:26:41+00:00\n",
      "  ‚úì lastConnectionStateChange: 2 valid timestamps\n",
      "    Range: 2025-09-08 22:14:16+00:00 to 2025-10-23 22:31:50+00:00\n",
      "üìÖ sites: Found timestamp columns - meta.timezone, statistics.counts.pendingUpdateDevice, statistics.percentages.wanUptime, statistics.wans.WAN.wanUptime\n",
      "  ‚úì statistics.counts.pendingUpdateDevice: 2 valid timestamps\n",
      "    Range: 1970-01-01 00:00:00 to 1970-01-01 00:00:00\n",
      "üìÖ devices: Found timestamp columns - updatedAt\n",
      "  ‚úì updatedAt: 1 valid timestamps\n",
      "    Range: 2025-10-23 22:31:52+00:00 to 2025-10-23 22:31:52+00:00\n",
      "\n",
      "üí° Tip: Use parsed timestamp columns for time-series analysis!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/rjr00hgj0txg4sd7_4l617tw0000gn/T/ipykernel_18866/393840987.py:28: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[f'{col}_parsed'] = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Look for timestamp columns and analyze temporal patterns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Searching for timestamp data...\\n\")\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # Find columns that might be timestamps\n",
    "    time_cols = [col for col in df.columns if any(word in col.lower() for word in ['time', 'date', 'created', 'updated', 'last', 'timestamp'])]\n",
    "    \n",
    "    if time_cols:\n",
    "        print(f\"üìÖ {name}: Found timestamp columns - {', '.join(time_cols)}\")\n",
    "        \n",
    "        for col in time_cols[:2]:  # Check first 2 time columns\n",
    "            sample = df[col].dropna()\n",
    "            if len(sample) > 0:\n",
    "                # Try to parse as datetime\n",
    "                try:\n",
    "                    if isinstance(sample.iloc[0], (int, float)):\n",
    "                        # Might be Unix timestamp (milliseconds or seconds)\n",
    "                        if sample.iloc[0] > 1e10:\n",
    "                            # Likely milliseconds\n",
    "                            df[f'{col}_parsed'] = pd.to_datetime(df[col], unit='ms', errors='coerce')\n",
    "                        else:\n",
    "                            # Likely seconds\n",
    "                            df[f'{col}_parsed'] = pd.to_datetime(df[col], unit='s', errors='coerce')\n",
    "                    else:\n",
    "                        df[f'{col}_parsed'] = pd.to_datetime(df[col], errors='coerce')\n",
    "                    \n",
    "                    valid_times = df[f'{col}_parsed'].dropna()\n",
    "                    if len(valid_times) > 0:\n",
    "                        print(f\"  ‚úì {col}: {len(valid_times)} valid timestamps\")\n",
    "                        print(f\"    Range: {valid_times.min()} to {valid_times.max()}\")\n",
    "                        \n",
    "                        # Show distribution if many timestamps\n",
    "                        if len(valid_times) > 10:\n",
    "                            df[f'{col}_date'] = df[f'{col}_parsed'].dt.date\n",
    "                            daily_counts = df[f'{col}_date'].value_counts().sort_index()\n",
    "                            print(f\"    Daily distribution (last 5 days):\")\n",
    "                            for date, count in list(daily_counts.items())[-5:]:\n",
    "                                print(f\"      {date}: {count}\")\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "print(\"\\nüí° Tip: Use parsed timestamp columns for time-series analysis!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Filter Examples\n",
    "\n",
    "Practical examples of searching and filtering your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SEARCH AND FILTER EXAMPLES\n",
      "============================================================\n",
      "\n",
      "1. Search Devices by Name/Model\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SEARCH AND FILTER EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Example 1: Search for specific devices\n",
    "if 'devices' in dataframes:\n",
    "    df = dataframes['devices']\n",
    "    print(\"1. Search Devices by Name/Model\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if 'name' in df.columns:\n",
    "        print(\"\\nDevices with names containing 'Dream' or 'UDM':\")\n",
    "        matching = df[df['name'].str.contains('Dream|UDM', case=False, na=False)]\n",
    "        if len(matching) > 0:\n",
    "            # Use vectorized operations instead of iterating\n",
    "            result = matching[['name', 'model']].fillna('N/A')\n",
    "            for name, model in result.values:\n",
    "                print(f\"  - {name} ({model})\")\n",
    "        else:\n",
    "            print(\"  No matches found\")\n",
    "    \n",
    "    if 'model' in df.columns:\n",
    "        print(\"\\nUnique device models:\")\n",
    "        # Use value_counts instead of manual counting\n",
    "        model_counts = df['model'].value_counts().head(10)\n",
    "        print(model_counts.to_string())\n",
    "\n",
    "# Example 2: Filter clients by SSID\n",
    "if 'clients' in dataframes:\n",
    "    df = dataframes['clients']\n",
    "    print(\"\\n\\n2. Filter Clients\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if 'essid' in df.columns:\n",
    "        print(\"\\nClients grouped by SSID:\")\n",
    "        # Use groupby instead of iterating\n",
    "        for ssid, group in df.groupby('essid').head(5).groupby('essid'):\n",
    "            print(f\"\\n  SSID: {ssid} ({len(df[df['essid'] == ssid])} clients)\")\n",
    "            if 'hostname' in group.columns:\n",
    "                hostnames = group['hostname'].dropna().unique()[:5]\n",
    "                print(f\"    Hostnames: {', '.join(hostnames)}\")\n",
    "\n",
    "# Example 3: Network configurations\n",
    "if 'networks' in dataframes:\n",
    "    df = dataframes['networks']\n",
    "    print(\"\\n\\n3. Network Configurations\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if 'purpose' in df.columns:\n",
    "        print(\"\\nNetworks by purpose:\")\n",
    "        # Use groupby and agg instead of iterating\n",
    "        grouped = df.groupby('purpose', as_index=False).agg({\n",
    "            'purpose': 'count',\n",
    "            **{col: lambda x: ', '.join(x.dropna().head(5).tolist()) \n",
    "               for col in df.columns if col == 'name'}\n",
    "        })\n",
    "        for _, row in grouped.iterrows():\n",
    "            print(f\"\\n  {row['purpose']}: network(s)\")\n",
    "            if 'name' in row.index:\n",
    "                print(f\"    Names: {row.get('name', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries\n",
    "\n",
    "More complex queries and aggregations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostId</th>\n",
       "      <th>devices</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>updatedAt_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74ACB93D0FFB0000000004AEDD420000000004E4063400...</td>\n",
       "      <td>[{'id': '74ACB93D0FFB', 'mac': '74ACB93D0FFB',...</td>\n",
       "      <td>2025-10-23T22:31:52Z</td>\n",
       "      <td>2025-10-23 22:31:52+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              hostId  \\\n",
       "0  74ACB93D0FFB0000000004AEDD420000000004E4063400...   \n",
       "\n",
       "                                             devices             updatedAt  \\\n",
       "0  [{'id': '74ACB93D0FFB', 'mac': '74ACB93D0FFB',...  2025-10-23T22:31:52Z   \n",
       "\n",
       "           updatedAt_parsed  \n",
       "0 2025-10-23 22:31:52+00:00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export All Data for Further Analysis\n",
    "\n",
    "Export all DataFrames to various formats for external analysis tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED QUERIES AND AGGREGATIONS\n",
      "============================================================\n",
      "\n",
      "1. Cross-DataFrame Analysis\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "3. Summary Statistics\n",
      "------------------------------------------------------------\n",
      "\n",
      "hosts - Numeric columns:\n",
      "                                                                           mean     min      max\n",
      "reportedState.firmware_version                                              NaN     NaN      NaN\n",
      "reportedState.host_type                                                 29960.5     0.0  59921.0\n",
      "reportedState.inform_port                                                8080.0  8080.0   8080.0\n",
      "reportedState.mgmt_port                                                  4443.0   443.0   8443.0\n",
      "reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.day      0.0     0.0      0.0\n",
      "\n",
      "sites - Numeric columns:\n",
      "                                        mean  min  max\n",
      "statistics.counts.criticalNotification   0.0  0.0  0.0\n",
      "statistics.counts.gatewayDevice          0.5  0.0  1.0\n",
      "statistics.counts.guestClient            0.0  0.0  0.0\n",
      "statistics.counts.lanConfiguration       1.0  1.0  1.0\n",
      "statistics.counts.offlineDevice          0.0  0.0  0.0\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ADVANCED QUERIES AND AGGREGATIONS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# 1. Cross-join analysis (if possible)\n",
    "print(\"1. Cross-DataFrame Analysis\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Devices and their IPs - use vectorized operations\n",
    "if 'devices' in dataframes:\n",
    "    df = dataframes['devices']\n",
    "    if 'ip' in df.columns:\n",
    "        device_ips = df['ip'].dropna().nunique()\n",
    "        print(f\"\\nDevice IPs: {device_ips} unique IPs\")\n",
    "        if all(col in df.columns for col in ['name', 'ip', 'model']):\n",
    "            print(\"\\nDevices with IPs:\")\n",
    "            device_info = df[['name', 'ip', 'model']].dropna(subset=['ip']).head(10)\n",
    "            # Use apply or to_string instead of iterating\n",
    "            print(device_info.to_string(index=False))\n",
    "\n",
    "# Client and device correlation - use set operations\n",
    "if 'clients' in dataframes and 'devices' in dataframes:\n",
    "    client_ips = set(dataframes['clients']['ip'].dropna().unique()) if 'ip' in dataframes['clients'].columns else set()\n",
    "    device_ips = set(dataframes['devices']['ip'].dropna().unique()) if 'ip' in dataframes['devices'].columns else set()\n",
    "    \n",
    "    if client_ips or device_ips:\n",
    "        print(\"\\n\\n2. IP Address Analysis\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Client IPs: {len(client_ips)}\")\n",
    "        print(f\"Device IPs: {len(device_ips)}\")\n",
    "        \n",
    "        overlapping = client_ips & device_ips  # Set intersection\n",
    "        if overlapping:\n",
    "            print(f\"Overlapping IPs (clients that might be devices): {len(overlapping)}\")\n",
    "            print(f\"  Sample: {list(overlapping)[:5]}\")\n",
    "\n",
    "# 3. Summary statistics - use describe() directly\n",
    "print(\"\\n\\n3. Summary Statistics\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\n{name} - Numeric columns:\")\n",
    "        # Use describe() directly instead of manual stats\n",
    "        stats = df[numeric_cols[:5]].describe().T[['mean', 'min', 'max']]\n",
    "        print(stats.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting all data to 'unifi_comprehensive_export'...\n",
      "\n",
      "‚úì CSV: hosts                ‚Üí unifi_comprehensive_export/hosts_20251102_201523.csv\n",
      "‚úì CSV: sites                ‚Üí unifi_comprehensive_export/sites_20251102_201523.csv\n",
      "‚úì CSV: devices              ‚Üí unifi_comprehensive_export/devices_20251102_201523.csv\n",
      "\n",
      "‚ö†Ô∏è  openpyxl not installed - skipping Excel export\n",
      "   Install with: pip install openpyxl\n",
      "‚úì Metadata: ‚Üí unifi_comprehensive_export/metadata_20251102_201523.json\n",
      "\n",
      "============================================================\n",
      "‚úì Export complete!\n",
      "   - 3 CSV files\n",
      "   - 1 Excel workbook (if available)\n",
      "   - 1 metadata JSON file\n",
      "   Location: /Users/lou/Downloads/mid-linux-container-recipe.zurich-07-01-2025__patch2-09-24-2025_10-12-2025_0904.linux.x86-64/unifi_comprehensive_export\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Create comprehensive export\n",
    "export_dir = \"unifi_comprehensive_export\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"Exporting all data to '{export_dir}'...\\n\")\n",
    "\n",
    "# 1. Export all DataFrames to CSV\n",
    "csv_count = 0\n",
    "for name, df in dataframes.items():\n",
    "    csv_file = f\"{export_dir}/{name}_{timestamp}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    csv_count += 1\n",
    "    print(f\"‚úì CSV: {name:20s} ‚Üí {csv_file}\")\n",
    "\n",
    "# 2. Export all DataFrames to Excel (one workbook with multiple sheets)\n",
    "try:\n",
    "    excel_file = f\"{export_dir}/unifi_all_data_{timestamp}.xlsx\"\n",
    "    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "        for name, df in dataframes.items():\n",
    "            # Excel sheet names have limitations\n",
    "            sheet_name = name[:31]  # Excel sheet name limit\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"\\n‚úì Excel: All DataFrames ‚Üí {excel_file}\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  openpyxl not installed - skipping Excel export\")\n",
    "    print(\"   Install with: pip install openpyxl\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Excel export failed: {e}\")\n",
    "\n",
    "# 3. Export summary metadata as JSON\n",
    "metadata = {\n",
    "    'export_timestamp': timestamp,\n",
    "    'total_dataframes': len(dataframes),\n",
    "    'dataframes': {}\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    metadata['dataframes'][name] = {\n",
    "        'rows': int(df.shape[0]),\n",
    "        'columns': int(df.shape[1]),\n",
    "        'column_names': df.columns.tolist(),\n",
    "        'dtypes': {str(k): str(v) for k, v in df.dtypes.items()}\n",
    "    }\n",
    "\n",
    "metadata_file = f\"{export_dir}/metadata_{timestamp}.json\"\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Metadata: ‚Üí {metadata_file}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Export complete!\")\n",
    "print(f\"   - {csv_count} CSV files\")\n",
    "print(f\"   - 1 Excel workbook (if available)\")\n",
    "print(f\"   - 1 metadata JSON file\")\n",
    "print(f\"   Location: {os.path.abspath(export_dir)}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "All DataFrames are stored in the `dataframes` dictionary. Quick access guide:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK REFERENCE GUIDE\n",
      "============================================================\n",
      "\n",
      "üìä Available DataFrames:\n",
      "  ‚Ä¢ dataframes['devices']\n",
      "    ‚Üí 1 rows √ó 4 columns\n",
      "\n",
      "  ‚Ä¢ dataframes['hosts']\n",
      "    ‚Üí 2 rows √ó 153 columns\n",
      "    ‚Üí Key columns: id\n",
      "\n",
      "  ‚Ä¢ dataframes['sites']\n",
      "    ‚Üí 2 rows √ó 45 columns\n",
      "\n",
      "\n",
      "üí° Useful Commands:\n",
      "  # View all DataFrames\n",
      "  list(dataframes.keys())\n",
      "\n",
      "  # Access a DataFrame\n",
      "  df = dataframes['devices']\n",
      "\n",
      "  # View DataFrame\n",
      "  dataframes['devices'].head()\n",
      "\n",
      "  # Filter data\n",
      "  dataframes['devices'][dataframes['devices']['model'] == 'UDM']\n",
      "\n",
      "  # Group by\n",
      "  dataframes['clients'].groupby('essid').size()\n",
      "\n",
      "  # Export\n",
      "  dataframes['devices'].to_csv('devices.csv', index=False)\n",
      "\n",
      "============================================================\n",
      "Happy exploring! üöÄ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"QUICK REFERENCE GUIDE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Use list comprehension and string formatting more efficiently\n",
    "key_cols_template = ['name', 'id', 'ip', 'mac', 'model', 'hostname', 'essid']\n",
    "\n",
    "dataframe_info = [\n",
    "    (name, df, [col for col in key_cols_template if col in df.columns])\n",
    "    for name, df in sorted(dataframes.items())\n",
    "]\n",
    "\n",
    "print(\"üìä Available DataFrames:\")\n",
    "for name, df, key_cols in dataframe_info:\n",
    "    print(f\"  ‚Ä¢ dataframes['{name}']\")\n",
    "    print(f\"    ‚Üí {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    if key_cols:\n",
    "        print(f\"    ‚Üí Key columns: {', '.join(key_cols[:5])}\")\n",
    "    print()\n",
    "\n",
    "commands = {\n",
    "    \"View all DataFrames\": \"list(dataframes.keys())\",\n",
    "    \"Access a DataFrame\": \"df = dataframes['devices']\",\n",
    "    \"View DataFrame\": \"dataframes['devices'].head()\",\n",
    "    \"Filter data\": \"dataframes['devices'][dataframes['devices']['model'] == 'UDM']\",\n",
    "    \"Group by\": \"dataframes['clients'].groupby('essid').size()\",\n",
    "    \"Export\": \"dataframes['devices'].to_csv('devices.csv', index=False)\"\n",
    "}\n",
    "\n",
    "print(\"\\nüí° Useful Commands:\")\n",
    "for desc, cmd in commands.items():\n",
    "    print(f\"  # {desc}\")\n",
    "    print(f\"  {cmd}\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Happy exploring! üöÄ\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer Relational Schema from Data\n",
    "\n",
    "Analyze the actual data structure to infer a normalized relational schema with relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCHEMA INFERENCE FROM ACTUAL DATA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Analyzing: HOSTS\n",
      "============================================================\n",
      "Shape: 2 rows √ó 153 columns\n",
      "\n",
      "Primary Key Candidates: ['id', 'hardwareId', 'type', 'registrationTime', 'lastConnectionStateChange', 'latestBackupTime', 'reportedState.controller_uuid', 'reportedState.host_type', 'reportedState.hostname', 'reportedState.mgmt_port', 'reportedState.name', 'reportedState.state', 'reportedState.version', 'lastConnectionStateChange_parsed']\n",
      "Foreign Key Candidates: ['reportedState.hardware_id', 'reportedState.override_inform_host', 'userData.features.deviceGroups', 'userData.localId', 'userData.roleId', 'reportedState.anonid', 'reportedState.deviceErrorCode', 'reportedState.deviceState', 'reportedState.deviceStateLastChanged', 'reportedState.features.deviceList.autolinkDevices', 'reportedState.features.deviceList.partialUpdates', 'reportedState.features.deviceList.ucp4Events', 'reportedState.features.identity.hostingIdentityHubScore', 'reportedState.features.identity.standard', 'reportedState.features.identity.ucs', 'reportedState.features.identity.ucsAgent', 'reportedState.features.identity.ucsRemoteAccessViaUOS', 'reportedState.features.identity.unifiedAdminsUsersPage', 'reportedState.features.mspBridgeModesSupported', 'reportedState.features.uidService', 'reportedState.hardware.cpu.id', 'reportedState.hardware.qrid', 'reportedState.hardware.sysid', 'reportedState.hardware.uuid', 'reportedState.uidb.guid', 'reportedState.uidb.id', 'reportedState.uidb.images.default', 'reportedState.uidb.images.mobile-connection', 'reportedState.uidb.images.mobile-internet-connected', 'reportedState.uidb.images.mobile-no-internet', 'reportedState.uidb.images.nopadding', 'reportedState.uidb.images.topology']\n",
      "Nested Columns: ['userData.permissions.network.management', 'reportedState.ipAddrs', 'userData.apps', 'userData.consoleGroupMembers', 'userData.controllers', 'userData.permissions.access.management', 'userData.permissions.calculus.management', 'userData.permissions.connect.management', 'userData.permissions.drive.management', 'userData.permissions.innerspace.management', 'userData.permissions.led.management', 'userData.permissions.olympus.management', 'userData.permissions.protect.management', 'userData.permissions.system.management.location', 'userData.permissions.system.management.user', 'userData.permissions.talk-relay.management', 'userData.permissions.talk.management', 'reportedState.apps', 'reportedState.availableChannels', 'reportedState.consolesOnSameLocalNetwork', 'reportedState.controllers', 'reportedState.internetIssues5min.periods', 'reportedState.unadoptedUnifiOSDevices', 'reportedState.wans']\n",
      "\n",
      "Column Summary:\n",
      "  id                             | object     |    2/2 non-null | 2 unique\n",
      "  hardwareId                     | object     |    2/2 non-null | 2 unique\n",
      "  type                           | object     |    2/2 non-null | 2 unique\n",
      "  ipAddress                      | object     |    2/2 non-null | 1 unique\n",
      "  owner                          | bool       |    2/2 non-null | 1 unique\n",
      "  isBlocked                      | bool       |    2/2 non-null | 1 unique\n",
      "  registrationTime               | object     |    2/2 non-null | 2 unique\n",
      "  lastConnectionStateChange      | object     |    2/2 non-null | 2 unique\n",
      "  latestBackupTime               | object     |    2/2 non-null | 2 unique\n",
      "  userData.permissions.network.management | object     |    2/2 non-null | N/A (list/dict) unique\n",
      "  userData.status                | object     |    2/2 non-null | 1 unique\n",
      "  reportedState.controller_uuid  | object     |    2/2 non-null | 2 unique\n",
      "  reportedState.firmware_version | float64    |    0/2 non-null | 0 unique\n",
      "  reportedState.hardware_id      | object     |    1/2 non-null | 1 unique\n",
      "  reportedState.host_type        | int64      |    2/2 non-null | 2 unique\n",
      "\n",
      "============================================================\n",
      "Analyzing: SITES\n",
      "============================================================\n",
      "Shape: 2 rows √ó 45 columns\n",
      "\n",
      "Primary Key Candidates: ['siteId', 'hostId', 'meta.timezone', 'statistics.counts.gatewayDevice', 'statistics.counts.totalDevice', 'statistics.counts.wanConfiguration', 'statistics.counts.wifiClient', 'statistics.counts.wifiConfiguration', 'statistics.counts.wiredClient']\n",
      "Foreign Key Candidates: ['statistics.counts.offlineDevice', 'statistics.counts.offlineGatewayDevice', 'statistics.counts.offlineWifiDevice', 'statistics.counts.offlineWiredDevice', 'statistics.counts.pendingUpdateDevice', 'statistics.counts.wifiDevice', 'statistics.counts.wiredDevice', 'statistics.gateway.hardwareId', 'statistics.counts.pendingUpdateDevice_parsed']\n",
      "Nested Columns: ['statistics.internetIssues', 'statistics.wans.WAN.wanIssues']\n",
      "\n",
      "Column Summary:\n",
      "  siteId                         | object     |    2/2 non-null | 2 unique\n",
      "  hostId                         | object     |    2/2 non-null | 2 unique\n",
      "  permission                     | object     |    2/2 non-null | 1 unique\n",
      "  isOwner                        | bool       |    2/2 non-null | 1 unique\n",
      "  meta.desc                      | object     |    2/2 non-null | 1 unique\n",
      "  meta.name                      | object     |    2/2 non-null | 1 unique\n",
      "  meta.timezone                  | object     |    2/2 non-null | 2 unique\n",
      "  statistics.counts.criticalNotification | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.gatewayDevice | int64      |    2/2 non-null | 2 unique\n",
      "  statistics.counts.guestClient  | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.lanConfiguration | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.offlineDevice | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.offlineGatewayDevice | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.offlineWifiDevice | int64      |    2/2 non-null | 1 unique\n",
      "  statistics.counts.offlineWiredDevice | int64      |    2/2 non-null | 1 unique\n",
      "\n",
      "============================================================\n",
      "Analyzing: DEVICES\n",
      "============================================================\n",
      "Shape: 1 rows √ó 4 columns\n",
      "\n",
      "Primary Key Candidates: ['hostId', 'updatedAt', 'updatedAt_parsed']\n",
      "Foreign Key Candidates: None\n",
      "Nested Columns: ['devices']\n",
      "\n",
      "Column Summary:\n",
      "  hostId                         | object     |    1/1 non-null | 1 unique\n",
      "  devices                        | object     |    1/1 non-null | N/A (list/dict) unique\n",
      "  updatedAt                      | object     |    1/1 non-null | 1 unique\n",
      "  updatedAt_parsed               | datetime64[ns, UTC] |    1/1 non-null | 1 unique\n",
      "\n",
      "============================================================\n",
      "ANALYZED 3 DATA TABLES\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCHEMA INFERENCE FROM ACTUAL DATA\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Analyze each DataFrame structure\n",
    "schema_info = {}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing: {name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")\n",
    "    \n",
    "    # Identify potential keys\n",
    "    id_cols = [c for c in df.columns if 'id' in c.lower() and c.lower() not in ['device', 'network']]\n",
    "    unique_cols = []\n",
    "    foreign_key_candidates = []\n",
    "    \n",
    "    # Check for unique identifiers (skip unhashable types like lists/dicts)\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            # Check if column has hashable values (not lists/dicts)\n",
    "            sample = df[col].dropna()\n",
    "            if len(sample) > 0:\n",
    "                first_val = sample.iloc[0]\n",
    "                if isinstance(first_val, (list, dict)):\n",
    "                    continue  # Skip unhashable types\n",
    "            # Now safe to check nunique\n",
    "            if df[col].nunique() == len(df) and df[col].notna().sum() > 0:\n",
    "                unique_cols.append(col)\n",
    "        except (TypeError, ValueError):\n",
    "            # Skip columns that cause errors with nunique\n",
    "            continue\n",
    "    \n",
    "    # Check for potential foreign keys (values that appear in other tables)\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            # Skip unhashable types\n",
    "            sample = df[col].dropna()\n",
    "            if len(sample) > 0:\n",
    "                first_val = sample.iloc[0]\n",
    "                if isinstance(first_val, (list, dict)):\n",
    "                    continue\n",
    "            # Check if column name suggests FK and is not unique\n",
    "            if any(keyword in col.lower() for keyword in ['id', 'host', 'site', 'device', 'network']):\n",
    "                if df[col].nunique() < len(df):  # Not unique = might be FK\n",
    "                    foreign_key_candidates.append(col)\n",
    "        except (TypeError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    # Analyze data types\n",
    "    data_types = {\n",
    "        'categorical': list(df.select_dtypes(include=['object', 'bool']).columns),\n",
    "        'numeric': list(df.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        'datetime': [c for c in df.columns if 'time' in c.lower() or 'date' in c.lower()]\n",
    "    }\n",
    "    \n",
    "    # Look for nested structures (dict/list columns)\n",
    "    nested_cols = []\n",
    "    for col in df.columns:\n",
    "        sample = df[col].dropna()\n",
    "        if len(sample) > 0:\n",
    "            val = sample.iloc[0]\n",
    "            if isinstance(val, (dict, list)):\n",
    "                nested_cols.append((col, type(val).__name__))\n",
    "    \n",
    "    schema_info[name] = {\n",
    "        'columns': list(df.columns),\n",
    "        'row_count': len(df),\n",
    "        'id_cols': id_cols,\n",
    "        'unique_cols': unique_cols,\n",
    "        'foreign_key_candidates': foreign_key_candidates,\n",
    "        'data_types': data_types,\n",
    "        'nested_cols': nested_cols,\n",
    "        'sample_data': df.head(1).to_dict('records')[0] if len(df) > 0 else {}\n",
    "    }\n",
    "    \n",
    "    print(f\"Primary Key Candidates: {unique_cols if unique_cols else 'None found (might need composite)'}\")\n",
    "    print(f\"Foreign Key Candidates: {foreign_key_candidates if foreign_key_candidates else 'None'}\")\n",
    "    print(f\"Nested Columns: {[c[0] for c in nested_cols] if nested_cols else 'None'}\")\n",
    "    \n",
    "    # Show column summary\n",
    "    print(f\"\\nColumn Summary:\")\n",
    "    for col in df.columns[:15]:\n",
    "        dtype = str(df[col].dtype)\n",
    "        non_null = df[col].notna().sum()\n",
    "        try:\n",
    "            # Check if column has hashable values\n",
    "            sample = df[col].dropna()\n",
    "            if len(sample) > 0:\n",
    "                first_val = sample.iloc[0]\n",
    "                if isinstance(first_val, (list, dict)):\n",
    "                    unique = \"N/A (list/dict)\"\n",
    "                else:\n",
    "                    unique = df[col].nunique()\n",
    "            else:\n",
    "                unique = 0\n",
    "        except (TypeError, ValueError):\n",
    "            unique = \"N/A\"\n",
    "        print(f\"  {col:30s} | {dtype:10s} | {non_null:4d}/{len(df)} non-null | {unique} unique\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ANALYZED {len(schema_info)} DATA TABLES\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Relational Schema\n",
    "\n",
    "Based on the analysis, here's the inferred relational schema with relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RELATIONAL SCHEMA\n",
      "============================================================\n",
      "\n",
      "TABLES AND COLUMNS:\n",
      "\n",
      "üìä HOSTS\n",
      "------------------------------------------------------------\n",
      "  PRIMARY KEY: id\n",
      "\n",
      "  COLUMNS:\n",
      "    id                             object          NOT NULL   [PK]\n",
      "    hardwareId                     object          NOT NULL  \n",
      "    type                           object          NOT NULL  \n",
      "    ipAddress                      object          NOT NULL  \n",
      "    owner                          bool            NOT NULL  \n",
      "    isBlocked                      bool            NOT NULL  \n",
      "    registrationTime               object          NOT NULL  \n",
      "    lastConnectionStateChange      object          NOT NULL  \n",
      "    latestBackupTime               object          NOT NULL  \n",
      "    userData.permissions.network.management object          NOT NULL  \n",
      "    userData.status                object          NOT NULL  \n",
      "    reportedState.controller_uuid  object          NOT NULL  \n",
      "    reportedState.firmware_version float64         NULL      \n",
      "    reportedState.hardware_id      object          NULL      \n",
      "    reportedState.host_type        int64           NOT NULL  \n",
      "    reportedState.hostname         object          NOT NULL  \n",
      "    reportedState.inform_port      float64         NULL      \n",
      "    reportedState.ipAddrs          object          NOT NULL  \n",
      "    reportedState.mgmt_port        int64           NOT NULL  \n",
      "    reportedState.name             object          NOT NULL  \n",
      "    reportedState.override_inform_host object          NULL      \n",
      "    reportedState.release_channel  object          NULL      \n",
      "    reportedState.state            object          NOT NULL  \n",
      "    reportedState.version          object          NOT NULL  \n",
      "    userData.apps                  object          NULL      \n",
      "    userData.consoleGroupMembers   object          NULL      \n",
      "    userData.controllers           object          NULL      \n",
      "    userData.email                 object          NULL      \n",
      "    userData.features.deviceGroups object          NULL      \n",
      "    userData.features.floorplan.canEdit object          NULL      \n",
      "    userData.features.floorplan.canView object          NULL      \n",
      "    userData.features.manageApplications object          NULL      \n",
      "    userData.features.notifications object          NULL      \n",
      "    userData.features.webrtc.iceRestart object          NULL      \n",
      "    userData.features.webrtc.mediaStreams object          NULL      \n",
      "    userData.features.webrtc.mediaStreamsAV1 object          NULL      \n",
      "    userData.features.webrtc.mediaStreamsH265 object          NULL      \n",
      "    userData.features.webrtc.twoWayAudio object          NULL      \n",
      "    userData.fullName              object          NULL      \n",
      "    userData.localId               object          NULL      \n",
      "    userData.permissions.access.management object          NULL      \n",
      "    userData.permissions.calculus.management object          NULL      \n",
      "    userData.permissions.connect.management object          NULL      \n",
      "    userData.permissions.drive.management object          NULL      \n",
      "    userData.permissions.innerspace.management object          NULL      \n",
      "    userData.permissions.led.management object          NULL      \n",
      "    userData.permissions.olympus.management object          NULL      \n",
      "    userData.permissions.protect.management object          NULL      \n",
      "    userData.permissions.system.management.location object          NULL      \n",
      "    userData.permissions.system.management.user object          NULL      \n",
      "    userData.permissions.talk-relay.management object          NULL      \n",
      "    userData.permissions.talk.management object          NULL      \n",
      "    userData.role                  object          NULL      \n",
      "    userData.roleId                object          NULL      \n",
      "    reportedState.anonid           object          NULL      \n",
      "    reportedState.apps             object          NULL      \n",
      "    reportedState.autoUpdate.includeApplications object          NULL      \n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.applications object          NULL      \n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.day float64         NULL      \n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.frequency object          NULL      \n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.hour float64         NULL      \n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.firmware object          NULL      \n",
      "    reportedState.autoUpdate.schedule.day float64         NULL      \n",
      "    reportedState.autoUpdate.schedule.frequency object          NULL      \n",
      "    reportedState.autoUpdate.schedule.hour float64         NULL      \n",
      "    reportedState.availableChannels object          NULL      \n",
      "    reportedState.consolesOnSameLocalNetwork object          NULL      \n",
      "    reportedState.controllers      object          NULL      \n",
      "    reportedState.deviceErrorCode  float64         NULL      \n",
      "    reportedState.deviceState      object          NULL      \n",
      "    reportedState.deviceStateLastChanged float64         NULL      \n",
      "    reportedState.directConnectDomain object          NULL      \n",
      "    reportedState.features.alarmManager object          NULL      \n",
      "    reportedState.features.apiIntegration object          NULL      \n",
      "    reportedState.features.applications.access.mspPlayback object          NULL      \n",
      "    reportedState.features.captiveProxy object          NULL      \n",
      "    reportedState.features.cloud.applicationEvents object          NULL      \n",
      "    reportedState.features.cloud.applicationEventsHttp object          NULL      \n",
      "    reportedState.features.cloud.ucp4GuestConnection object          NULL      \n",
      "    reportedState.features.cloudBackup object          NULL      \n",
      "    reportedState.features.customSmtpServer object          NULL      \n",
      "    reportedState.features.deviceList.autolinkDevices object          NULL      \n",
      "    reportedState.features.deviceList.partialUpdates object          NULL      \n",
      "    reportedState.features.deviceList.ucp4Events object          NULL      \n",
      "    reportedState.features.directRemoteConnection object          NULL      \n",
      "    reportedState.features.hasBezel object          NULL      \n",
      "    reportedState.features.hasGateway object          NULL      \n",
      "    reportedState.features.hasLCM  object          NULL      \n",
      "    reportedState.features.hasLED  object          NULL      \n",
      "    reportedState.features.identity.hostingIdentityHubScore float64         NULL      \n",
      "    reportedState.features.identity.standard object          NULL      \n",
      "    reportedState.features.identity.ucs object          NULL      \n",
      "    reportedState.features.identity.ucsAgent object          NULL      \n",
      "    reportedState.features.identity.ucsRemoteAccessViaUOS object          NULL      \n",
      "    reportedState.features.identity.unifiedAdminsUsersPage object          NULL      \n",
      "    reportedState.features.infoApis.firmwareUpdate object          NULL      \n",
      "    reportedState.features.isAutomaticFailoverAvailable object          NULL      \n",
      "    reportedState.features.led.canSetColor object          NULL      \n",
      "    reportedState.features.mfa     object          NULL      \n",
      "    reportedState.features.mspBridgeModesSupported object          NULL      \n",
      "    reportedState.features.multiplePoolsSupport object          NULL      \n",
      "    reportedState.features.netInAppBackupSupport object          NULL      \n",
      "    reportedState.features.notifications object          NULL      \n",
      "    reportedState.features.sharedTokens object          NULL      \n",
      "    reportedState.features.snmpConfig object          NULL      \n",
      "    reportedState.features.supportForm object          NULL      \n",
      "    reportedState.features.syslog  object          NULL      \n",
      "    reportedState.features.teleport object          NULL      \n",
      "    reportedState.features.teleportState object          NULL      \n",
      "    reportedState.features.uidService object          NULL      \n",
      "    reportedState.features.updates.applicationReleaseChannels object          NULL      \n",
      "    reportedState.features.updates.applicationSchedules object          NULL      \n",
      "    reportedState.firmwareUpdate.latestAvailableVersion float64         NULL      \n",
      "    reportedState.hardware.bom     object          NULL      \n",
      "    reportedState.hardware.cpu.id  object          NULL      \n",
      "    reportedState.hardware.debianCodename object          NULL      \n",
      "    reportedState.hardware.firmwareVersion object          NULL      \n",
      "    reportedState.hardware.hwrev   float64         NULL      \n",
      "    reportedState.hardware.isUbios object          NULL      \n",
      "    reportedState.hardware.mac     object          NULL      \n",
      "    reportedState.hardware.name    object          NULL      \n",
      "    reportedState.hardware.qrid    object          NULL      \n",
      "    reportedState.hardware.reboot  object          NULL      \n",
      "    reportedState.hardware.serialno object          NULL      \n",
      "    reportedState.hardware.shortname object          NULL      \n",
      "    reportedState.hardware.subtype object          NULL      \n",
      "    reportedState.hardware.sysid   float64         NULL      \n",
      "    reportedState.hardware.upgrade object          NULL      \n",
      "    reportedState.hardware.uuid    object          NULL      \n",
      "    reportedState.internetIssues5min.periods object          NULL      \n",
      "    reportedState.ip               object          NULL      \n",
      "    reportedState.isStacked        object          NULL      \n",
      "    reportedState.isUbiosMigration object          NULL      \n",
      "    reportedState.location.lat     float64         NULL      \n",
      "    reportedState.location.long    float64         NULL      \n",
      "    reportedState.location.radius  float64         NULL      \n",
      "    reportedState.location.text    object          NULL      \n",
      "    reportedState.mac              object          NULL      \n",
      "    reportedState.releaseChannel   object          NULL      \n",
      "    reportedState.timezone         object          NULL      \n",
      "    reportedState.ucareState       float64         NULL      \n",
      "    reportedState.uidb.guid        object          NULL      \n",
      "    reportedState.uidb.id          object          NULL      \n",
      "    reportedState.uidb.images.default object          NULL      \n",
      "    reportedState.uidb.images.mobile-connection object          NULL      \n",
      "    reportedState.uidb.images.mobile-internet-connected object          NULL      \n",
      "    reportedState.uidb.images.mobile-no-internet object          NULL      \n",
      "    reportedState.uidb.images.nopadding object          NULL      \n",
      "    reportedState.uidb.images.topology object          NULL      \n",
      "    reportedState.unadoptedUnifiOSDevices object          NULL      \n",
      "    reportedState.wans             object          NULL      \n",
      "    registrationTime_parsed        datetime64[ns, UTC] NULL      \n",
      "    lastConnectionStateChange_parsed datetime64[ns, UTC] NOT NULL  \n",
      "\n",
      "üìä SITES\n",
      "------------------------------------------------------------\n",
      "  PRIMARY KEY: siteId\n",
      "\n",
      "  COLUMNS:\n",
      "    siteId                         object          NOT NULL   [PK]\n",
      "    hostId                         object          NOT NULL  \n",
      "    permission                     object          NOT NULL  \n",
      "    isOwner                        bool            NOT NULL  \n",
      "    meta.desc                      object          NOT NULL  \n",
      "    meta.name                      object          NOT NULL  \n",
      "    meta.timezone                  object          NOT NULL  \n",
      "    statistics.counts.criticalNotification int64           NOT NULL  \n",
      "    statistics.counts.gatewayDevice int64           NOT NULL  \n",
      "    statistics.counts.guestClient  int64           NOT NULL  \n",
      "    statistics.counts.lanConfiguration int64           NOT NULL  \n",
      "    statistics.counts.offlineDevice int64           NOT NULL  \n",
      "    statistics.counts.offlineGatewayDevice int64           NOT NULL  \n",
      "    statistics.counts.offlineWifiDevice int64           NOT NULL  \n",
      "    statistics.counts.offlineWiredDevice int64           NOT NULL  \n",
      "    statistics.counts.pendingUpdateDevice int64           NOT NULL  \n",
      "    statistics.counts.totalDevice  int64           NOT NULL  \n",
      "    statistics.counts.wanConfiguration int64           NOT NULL  \n",
      "    statistics.counts.wifiClient   int64           NOT NULL  \n",
      "    statistics.counts.wifiConfiguration int64           NOT NULL  \n",
      "    statistics.counts.wifiDevice   int64           NOT NULL  \n",
      "    statistics.counts.wiredClient  int64           NOT NULL  \n",
      "    statistics.counts.wiredDevice  int64           NOT NULL  \n",
      "    meta.gatewayMac                object          NULL      \n",
      "    statistics.gateway.hardwareId  object          NULL      \n",
      "    statistics.gateway.inspectionState object          NULL      \n",
      "    statistics.gateway.ipsMode     object          NULL      \n",
      "    statistics.gateway.ipsSignature.rulesCount float64         NULL      \n",
      "    statistics.gateway.ipsSignature.type object          NULL      \n",
      "    statistics.gateway.shortname   object          NULL      \n",
      "    statistics.internetIssues      object          NULL      \n",
      "    statistics.ispInfo.name        object          NULL      \n",
      "    statistics.ispInfo.organization object          NULL      \n",
      "    statistics.percentages.txRetry float64         NULL      \n",
      "    statistics.percentages.wanUptime float64         NULL      \n",
      "    statistics.wanMagic.available  object          NULL      \n",
      "    statistics.wanMagic.enabled    object          NULL      \n",
      "    statistics.wanMagic.subscribed object          NULL      \n",
      "    statistics.wans.WAN.externalIp object          NULL      \n",
      "    statistics.wans.WAN.ispInfo.name object          NULL      \n",
      "    statistics.wans.WAN.ispInfo.organization object          NULL      \n",
      "    statistics.wans.WAN.wanIssues  object          NULL      \n",
      "    statistics.wans.WAN.wanUptime  float64         NULL      \n",
      "    meta.timezone_parsed           datetime64[ns]  NULL      \n",
      "    statistics.counts.pendingUpdateDevice_parsed datetime64[ns]  NOT NULL  \n",
      "\n",
      "üìä DEVICES\n",
      "------------------------------------------------------------\n",
      "  PRIMARY KEY: hostId\n",
      "  FOREIGN KEYS:\n",
      "    hostId -> sites.hostId (1 matching values)\n",
      "\n",
      "  COLUMNS:\n",
      "    hostId                         object          NOT NULL   [PK] [FK]\n",
      "    devices                        object          NOT NULL  \n",
      "    updatedAt                      object          NOT NULL  \n",
      "    updatedAt_parsed               datetime64[ns, UTC] NOT NULL  \n",
      "\n",
      "\n",
      "============================================================\n",
      "ENTITY RELATIONSHIPS\n",
      "============================================================\n",
      "\n",
      "devices:\n",
      "  ‚Üí sites (via hostId)\n",
      "\n",
      "\n",
      "üí° This schema can be used to create SQL tables or a proper database!\n"
     ]
    }
   ],
   "source": [
    "# Map relationships between tables\n",
    "print(\"=\"*60)\n",
    "print(\"RELATIONAL SCHEMA\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Find relationships by matching column names across tables\n",
    "relationships = defaultdict(list)\n",
    "\n",
    "for table1_name, table1_info in schema_info.items():\n",
    "    df1 = dataframes[table1_name]\n",
    "    for table2_name, table2_info in schema_info.items():\n",
    "        if table1_name == table2_name:\n",
    "            continue\n",
    "        \n",
    "        # Check if any columns match (potential FK relationships)\n",
    "        for col1 in table1_info['columns']:\n",
    "            for col2 in table2_info['columns']:\n",
    "                if col1.lower() == col2.lower():\n",
    "                    # Check if values actually overlap\n",
    "                    if col1 in df1.columns and col2 in dataframes[table2_name].columns:\n",
    "                        try:\n",
    "                            # Skip unhashable types\n",
    "                            sample1 = df1[col1].dropna()\n",
    "                            sample2 = dataframes[table2_name][col2].dropna()\n",
    "                            if len(sample1) > 0 and len(sample2) > 0:\n",
    "                                if isinstance(sample1.iloc[0], (list, dict)) or isinstance(sample2.iloc[0], (list, dict)):\n",
    "                                    continue\n",
    "                            vals1 = set(df1[col1].dropna().unique())\n",
    "                            vals2 = set(dataframes[table2_name][col2].dropna().unique())\n",
    "                            overlap = vals1 & vals2\n",
    "                            if len(overlap) > 0 and len(vals1) <= len(vals2):\n",
    "                                # Likely FK: table1.col1 -> table2.col2\n",
    "                                relationships[table1_name].append({\n",
    "                                    'foreign_key': col1,\n",
    "                                    'references': table2_name,\n",
    "                                    'referenced_column': col2,\n",
    "                                    'overlap_count': len(overlap)\n",
    "                                })\n",
    "                        except (TypeError, ValueError):\n",
    "                            # Skip columns that can't be hashed/compared\n",
    "                            continue\n",
    "\n",
    "# Define schema for each table\n",
    "print(\"TABLES AND COLUMNS:\\n\")\n",
    "for table_name, info in schema_info.items():\n",
    "    print(f\"üìä {table_name.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Primary key\n",
    "    pk = info['unique_cols'][0] if info['unique_cols'] else info['id_cols'][0] if info['id_cols'] else None\n",
    "    if pk:\n",
    "        print(f\"  PRIMARY KEY: {pk}\")\n",
    "    else:\n",
    "        print(f\"  PRIMARY KEY: (composite or none identified)\")\n",
    "    \n",
    "    # Foreign keys\n",
    "    fks = relationships.get(table_name, [])\n",
    "    if fks:\n",
    "        print(f\"  FOREIGN KEYS:\")\n",
    "        for fk_info in fks:\n",
    "            print(f\"    {fk_info['foreign_key']} -> {fk_info['references']}.{fk_info['referenced_column']} ({fk_info['overlap_count']} matching values)\")\n",
    "    \n",
    "    # Columns grouped by type\n",
    "    print(f\"\\n  COLUMNS:\")\n",
    "    df = dataframes[table_name]\n",
    "    for col in info['columns']:\n",
    "        dtype = df[col].dtype\n",
    "        nullable = \"NULL\" if df[col].isna().any() else \"NOT NULL\"\n",
    "        \n",
    "        # Check if it's a FK\n",
    "        is_fk = any(fk['foreign_key'] == col for fk in fks)\n",
    "        fk_marker = \" [FK]\" if is_fk else \"\"\n",
    "        pk_marker = \" [PK]\" if col == pk else \"\"\n",
    "        \n",
    "        print(f\"    {col:30s} {str(dtype):15s} {nullable:10s}{pk_marker}{fk_marker}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Entity Relationship Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ENTITY RELATIONSHIPS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "if relationships:\n",
    "    for table, fks in relationships.items():\n",
    "        if fks:\n",
    "            print(f\"{table}:\")\n",
    "            for fk in fks:\n",
    "                print(f\"  ‚Üí {fk['references']} (via {fk['foreign_key']})\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"No explicit relationships found in column names.\")\n",
    "    print(\"Relationships may be implicit through nested structures.\")\n",
    "    \n",
    "print(f\"\\nüí° This schema can be used to create SQL tables or a proper database!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SQL CREATE Statements\n",
    "\n",
    "Create SQL DDL statements based on the inferred schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SQL CREATE TABLE STATEMENTS\n",
      "============================================================\n",
      "\n",
      "CREATE TABLE hosts (\n",
      "    id TEXT NOT NULL PRIMARY KEY,\n",
      "    hardwareId TEXT NOT NULL,\n",
      "    type TEXT NOT NULL,\n",
      "    ipAddress TEXT NOT NULL,\n",
      "    owner BOOLEAN NOT NULL,\n",
      "    isBlocked BOOLEAN NOT NULL,\n",
      "    registrationTime TEXT NOT NULL,\n",
      "    lastConnectionStateChange TEXT NOT NULL,\n",
      "    latestBackupTime TEXT NOT NULL,\n",
      "    userData.status TEXT NOT NULL,\n",
      "    reportedState.controller_uuid TEXT NOT NULL,\n",
      "    reportedState.firmware_version REAL,\n",
      "    reportedState.hardware_id TEXT,\n",
      "    reportedState.host_type INTEGER NOT NULL,\n",
      "    reportedState.hostname TEXT NOT NULL,\n",
      "    reportedState.inform_port REAL,\n",
      "    reportedState.mgmt_port INTEGER NOT NULL,\n",
      "    reportedState.name TEXT NOT NULL,\n",
      "    reportedState.override_inform_host TEXT,\n",
      "    reportedState.release_channel TEXT,\n",
      "    reportedState.state TEXT NOT NULL,\n",
      "    reportedState.version TEXT NOT NULL,\n",
      "    userData.email TEXT,\n",
      "    userData.features.deviceGroups TEXT,\n",
      "    userData.features.floorplan.canEdit TEXT,\n",
      "    userData.features.floorplan.canView TEXT,\n",
      "    userData.features.manageApplications TEXT,\n",
      "    userData.features.notifications TEXT,\n",
      "    userData.features.webrtc.iceRestart TEXT,\n",
      "    userData.features.webrtc.mediaStreams TEXT,\n",
      "    userData.features.webrtc.mediaStreamsAV1 TEXT,\n",
      "    userData.features.webrtc.mediaStreamsH265 TEXT,\n",
      "    userData.features.webrtc.twoWayAudio TEXT,\n",
      "    userData.fullName TEXT,\n",
      "    userData.localId TEXT,\n",
      "    userData.role TEXT,\n",
      "    userData.roleId TEXT,\n",
      "    reportedState.anonid TEXT,\n",
      "    reportedState.autoUpdate.includeApplications TEXT,\n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.applications TEXT,\n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.day REAL,\n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.frequency TEXT,\n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.defaultSchedule.hour REAL,\n",
      "    reportedState.autoUpdate.preferencesPrompt.unifiOS.firmware TEXT,\n",
      "    reportedState.autoUpdate.schedule.day REAL,\n",
      "    reportedState.autoUpdate.schedule.frequency TEXT,\n",
      "    reportedState.autoUpdate.schedule.hour REAL,\n",
      "    reportedState.deviceErrorCode REAL,\n",
      "    reportedState.deviceState TEXT,\n",
      "    reportedState.deviceStateLastChanged REAL,\n",
      "    reportedState.directConnectDomain TEXT,\n",
      "    reportedState.features.alarmManager TEXT,\n",
      "    reportedState.features.apiIntegration TEXT,\n",
      "    reportedState.features.applications.access.mspPlayback TEXT,\n",
      "    reportedState.features.captiveProxy TEXT,\n",
      "    reportedState.features.cloud.applicationEvents TEXT,\n",
      "    reportedState.features.cloud.applicationEventsHttp TEXT,\n",
      "    reportedState.features.cloud.ucp4GuestConnection TEXT,\n",
      "    reportedState.features.cloudBackup TEXT,\n",
      "    reportedState.features.customSmtpServer TEXT,\n",
      "    reportedState.features.deviceList.autolinkDevices TEXT,\n",
      "    reportedState.features.deviceList.partialUpdates TEXT,\n",
      "    reportedState.features.deviceList.ucp4Events TEXT,\n",
      "    reportedState.features.directRemoteConnection TEXT,\n",
      "    reportedState.features.hasBezel TEXT,\n",
      "    reportedState.features.hasGateway TEXT,\n",
      "    reportedState.features.hasLCM TEXT,\n",
      "    reportedState.features.hasLED TEXT,\n",
      "    reportedState.features.identity.hostingIdentityHubScore REAL,\n",
      "    reportedState.features.identity.standard TEXT,\n",
      "    reportedState.features.identity.ucs TEXT,\n",
      "    reportedState.features.identity.ucsAgent TEXT,\n",
      "    reportedState.features.identity.ucsRemoteAccessViaUOS TEXT,\n",
      "    reportedState.features.identity.unifiedAdminsUsersPage TEXT,\n",
      "    reportedState.features.infoApis.firmwareUpdate TEXT,\n",
      "    reportedState.features.isAutomaticFailoverAvailable TEXT,\n",
      "    reportedState.features.led.canSetColor TEXT,\n",
      "    reportedState.features.mfa TEXT,\n",
      "    reportedState.features.mspBridgeModesSupported TEXT,\n",
      "    reportedState.features.multiplePoolsSupport TEXT,\n",
      "    reportedState.features.netInAppBackupSupport TEXT,\n",
      "    reportedState.features.notifications TEXT,\n",
      "    reportedState.features.sharedTokens TEXT,\n",
      "    reportedState.features.snmpConfig TEXT,\n",
      "    reportedState.features.supportForm TEXT,\n",
      "    reportedState.features.syslog TEXT,\n",
      "    reportedState.features.teleport TEXT,\n",
      "    reportedState.features.teleportState TEXT,\n",
      "    reportedState.features.uidService TEXT,\n",
      "    reportedState.features.updates.applicationReleaseChannels TEXT,\n",
      "    reportedState.features.updates.applicationSchedules TEXT,\n",
      "    reportedState.firmwareUpdate.latestAvailableVersion REAL,\n",
      "    reportedState.hardware.bom TEXT,\n",
      "    reportedState.hardware.cpu.id TEXT,\n",
      "    reportedState.hardware.debianCodename TEXT,\n",
      "    reportedState.hardware.firmwareVersion TEXT,\n",
      "    reportedState.hardware.hwrev REAL,\n",
      "    reportedState.hardware.isUbios TEXT,\n",
      "    reportedState.hardware.mac TEXT,\n",
      "    reportedState.hardware.name TEXT,\n",
      "    reportedState.hardware.qrid TEXT,\n",
      "    reportedState.hardware.reboot TEXT,\n",
      "    reportedState.hardware.serialno TEXT,\n",
      "    reportedState.hardware.shortname TEXT,\n",
      "    reportedState.hardware.subtype TEXT,\n",
      "    reportedState.hardware.sysid REAL,\n",
      "    reportedState.hardware.upgrade TEXT,\n",
      "    reportedState.hardware.uuid TEXT,\n",
      "    reportedState.ip TEXT,\n",
      "    reportedState.isStacked TEXT,\n",
      "    reportedState.isUbiosMigration TEXT,\n",
      "    reportedState.location.lat REAL,\n",
      "    reportedState.location.long REAL,\n",
      "    reportedState.location.radius REAL,\n",
      "    reportedState.location.text TEXT,\n",
      "    reportedState.mac TEXT,\n",
      "    reportedState.releaseChannel TEXT,\n",
      "    reportedState.timezone TEXT,\n",
      "    reportedState.ucareState REAL,\n",
      "    reportedState.uidb.guid TEXT,\n",
      "    reportedState.uidb.id TEXT,\n",
      "    reportedState.uidb.images.default TEXT,\n",
      "    reportedState.uidb.images.mobile-connection TEXT,\n",
      "    reportedState.uidb.images.mobile-internet-connected TEXT,\n",
      "    reportedState.uidb.images.mobile-no-internet TEXT,\n",
      "    reportedState.uidb.images.nopadding TEXT,\n",
      "    reportedState.uidb.images.topology TEXT,\n",
      "    registrationTime_parsed TIMESTAMP,\n",
      "    lastConnectionStateChange_parsed TIMESTAMP NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE sites (\n",
      "    siteId TEXT NOT NULL PRIMARY KEY,\n",
      "    hostId TEXT NOT NULL,\n",
      "    permission TEXT NOT NULL,\n",
      "    isOwner BOOLEAN NOT NULL,\n",
      "    meta.desc TEXT NOT NULL,\n",
      "    meta.name TEXT NOT NULL,\n",
      "    meta.timezone TEXT NOT NULL,\n",
      "    statistics.counts.criticalNotification INTEGER NOT NULL,\n",
      "    statistics.counts.gatewayDevice INTEGER NOT NULL,\n",
      "    statistics.counts.guestClient INTEGER NOT NULL,\n",
      "    statistics.counts.lanConfiguration INTEGER NOT NULL,\n",
      "    statistics.counts.offlineDevice INTEGER NOT NULL,\n",
      "    statistics.counts.offlineGatewayDevice INTEGER NOT NULL,\n",
      "    statistics.counts.offlineWifiDevice INTEGER NOT NULL,\n",
      "    statistics.counts.offlineWiredDevice INTEGER NOT NULL,\n",
      "    statistics.counts.pendingUpdateDevice INTEGER NOT NULL,\n",
      "    statistics.counts.totalDevice INTEGER NOT NULL,\n",
      "    statistics.counts.wanConfiguration INTEGER NOT NULL,\n",
      "    statistics.counts.wifiClient INTEGER NOT NULL,\n",
      "    statistics.counts.wifiConfiguration INTEGER NOT NULL,\n",
      "    statistics.counts.wifiDevice INTEGER NOT NULL,\n",
      "    statistics.counts.wiredClient INTEGER NOT NULL,\n",
      "    statistics.counts.wiredDevice INTEGER NOT NULL,\n",
      "    meta.gatewayMac TEXT,\n",
      "    statistics.gateway.hardwareId TEXT,\n",
      "    statistics.gateway.inspectionState TEXT,\n",
      "    statistics.gateway.ipsMode TEXT,\n",
      "    statistics.gateway.ipsSignature.rulesCount REAL,\n",
      "    statistics.gateway.ipsSignature.type TEXT,\n",
      "    statistics.gateway.shortname TEXT,\n",
      "    statistics.ispInfo.name TEXT,\n",
      "    statistics.ispInfo.organization TEXT,\n",
      "    statistics.percentages.txRetry REAL,\n",
      "    statistics.percentages.wanUptime REAL,\n",
      "    statistics.wanMagic.available TEXT,\n",
      "    statistics.wanMagic.enabled TEXT,\n",
      "    statistics.wanMagic.subscribed TEXT,\n",
      "    statistics.wans.WAN.externalIp TEXT,\n",
      "    statistics.wans.WAN.ispInfo.name TEXT,\n",
      "    statistics.wans.WAN.ispInfo.organization TEXT,\n",
      "    statistics.wans.WAN.wanUptime REAL,\n",
      "    meta.timezone_parsed TIMESTAMP,\n",
      "    statistics.counts.pendingUpdateDevice_parsed TIMESTAMP NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE devices (\n",
      "    hostId TEXT NOT NULL PRIMARY KEY,\n",
      "    updatedAt TEXT NOT NULL,\n",
      "    updatedAt_parsed TIMESTAMP NOT NULL,\n",
      "    FOREIGN KEY (hostId) REFERENCES sites(hostId)\n",
      ");\n",
      "\n",
      "\n",
      "‚úì SQL schema saved to: unifi_schema.sql\n",
      "   3 CREATE TABLE statements\n"
     ]
    }
   ],
   "source": [
    "# SQL type mapping\n",
    "def pandas_to_sql_type(dtype_str):\n",
    "    \"\"\"Map pandas dtypes to SQL types\"\"\"\n",
    "    dtype_lower = str(dtype_str).lower()\n",
    "    if 'int' in dtype_lower:\n",
    "        return 'INTEGER'\n",
    "    elif 'float' in dtype_lower:\n",
    "        return 'REAL'\n",
    "    elif 'bool' in dtype_lower:\n",
    "        return 'BOOLEAN'\n",
    "    elif 'datetime' in dtype_lower or 'timestamp' in dtype_lower:\n",
    "        return 'TIMESTAMP'\n",
    "    else:\n",
    "        return 'TEXT'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SQL CREATE TABLE STATEMENTS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "sql_statements = []\n",
    "\n",
    "for table_name, info in schema_info.items():\n",
    "    df = dataframes[table_name]\n",
    "    \n",
    "    # Get primary key\n",
    "    pk = info['unique_cols'][0] if info['unique_cols'] else info['id_cols'][0] if info['id_cols'] else None\n",
    "    \n",
    "    # Get foreign keys\n",
    "    fks = relationships.get(table_name, [])\n",
    "    fk_cols = {fk['foreign_key']: fk for fk in fks}\n",
    "    \n",
    "    # Build CREATE TABLE statement\n",
    "    table_name_sql = table_name.replace('-', '_').replace(' ', '_')\n",
    "    sql = f\"CREATE TABLE {table_name_sql} (\\n\"\n",
    "    \n",
    "    columns_def = []\n",
    "    for col in info['columns']:\n",
    "        # Skip nested columns for now (would need separate tables)\n",
    "        if col in [c[0] for c in info['nested_cols']]:\n",
    "            continue\n",
    "            \n",
    "        sql_type = pandas_to_sql_type(df[col].dtype)\n",
    "        nullable = \"\" if df[col].isna().any() else \" NOT NULL\"\n",
    "        \n",
    "        col_def = f\"    {col} {sql_type}{nullable}\"\n",
    "        \n",
    "        # Add primary key constraint\n",
    "        if col == pk:\n",
    "            col_def += \" PRIMARY KEY\"\n",
    "        \n",
    "        columns_def.append(col_def)\n",
    "    \n",
    "    sql += \",\\n\".join(columns_def)\n",
    "    \n",
    "    # Add foreign key constraints\n",
    "    if fks:\n",
    "        sql += \",\\n\"\n",
    "        fk_constraints = []\n",
    "        for fk_info in fks:\n",
    "            ref_table = fk_info['references'].replace('-', '_').replace(' ', '_')\n",
    "            ref_col = fk_info['referenced_column']\n",
    "            fk_constraints.append(\n",
    "                f\"    FOREIGN KEY ({fk_info['foreign_key']}) REFERENCES {ref_table}({ref_col})\"\n",
    "            )\n",
    "        sql += \",\\n\".join(fk_constraints)\n",
    "    \n",
    "    sql += \"\\n);\"\n",
    "    \n",
    "    sql_statements.append(sql)\n",
    "    print(sql)\n",
    "    print()\n",
    "\n",
    "# Save to file\n",
    "if sql_statements:\n",
    "    sql_file = \"unifi_schema.sql\"\n",
    "    with open(sql_file, 'w') as f:\n",
    "        f.write(\"-- UniFi Database Schema\\n\")\n",
    "        f.write(\"-- Generated from API data analysis\\n\")\n",
    "        f.write(f\"-- {len(sql_statements)} tables\\n\\n\")\n",
    "        f.write(\"\\n\\n\".join(sql_statements))\n",
    "    \n",
    "    print(f\"\\n‚úì SQL schema saved to: {sql_file}\")\n",
    "    print(f\"   {len(sql_statements)} CREATE TABLE statements\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Relationship Diagram (ERD)\n",
    "\n",
    "Visual representation of the relational schema and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "erDiagram\n",
       "    hosts {\n",
       "        id string PK\n",
       "        hardwareId string\n",
       "        type string\n",
       "        ipAddress string\n",
       "        userData.status string\n",
       "        reportedState.controller_uuid string\n",
       "        reportedState.hardware_id string\n",
       "        reportedState.host_type number\n",
       "        ... 85 more columns\n",
       "    }\n",
       "\n",
       "    sites {\n",
       "        siteId string PK\n",
       "        hostId string\n",
       "        meta.name string\n",
       "        statistics.counts.offlineWifiDevice number\n",
       "        statistics.counts.wifiDevice number\n",
       "        meta.gatewayMac string\n",
       "        statistics.gateway.hardwareId string\n",
       "        statistics.gateway.ipsMode string\n",
       "        ... 28 more columns\n",
       "    }\n",
       "\n",
       "    devices {\n",
       "        hostId string PK\n",
       "        ... 1 more columns\n",
       "    }\n",
       "\n",
       "    devices ||--o{ sites : \"hostId\"\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì ERD Generated (3 tables, 1 relationships)\n"
     ]
    }
   ],
   "source": [
    "# Generate Mermaid ERD\n",
    "from IPython.display import Markdown, display\n",
    "from collections import defaultdict\n",
    "\n",
    "def sanitize_name(name):\n",
    "    \"\"\"Sanitize names for Mermaid (remove special chars, spaces)\"\"\"\n",
    "    return name.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "\n",
    "def sanitize_column_name(col_name):\n",
    "    \"\"\"Sanitize column names - Mermaid can handle most but escape quotes\"\"\"\n",
    "    return col_name.replace('\"', '\\\\\"')\n",
    "\n",
    "# Ensure relationships is defined (in case schema analysis wasn't run)\n",
    "if 'relationships' not in globals():\n",
    "    relationships = defaultdict(list)\n",
    "    # Quick relationship detection if schema_info exists\n",
    "    if 'schema_info' in globals():\n",
    "        for table1_name, table1_info in schema_info.items():\n",
    "            df1 = dataframes[table1_name]\n",
    "            for table2_name, table2_info in schema_info.items():\n",
    "                if table1_name == table2_name:\n",
    "                    continue\n",
    "                for col1 in table1_info['columns']:\n",
    "                    for col2 in table2_info['columns']:\n",
    "                        if col1.lower() == col2.lower():\n",
    "                            if col1 in df1.columns and col2 in dataframes[table2_name].columns:\n",
    "                                try:\n",
    "                                    # Skip unhashable types\n",
    "                                    sample1 = df1[col1].dropna()\n",
    "                                    sample2 = dataframes[table2_name][col2].dropna()\n",
    "                                    if len(sample1) > 0 and len(sample2) > 0:\n",
    "                                        if isinstance(sample1.iloc[0], (list, dict)) or isinstance(sample2.iloc[0], (list, dict)):\n",
    "                                            continue\n",
    "                                    vals1 = set(df1[col1].dropna().unique())\n",
    "                                    vals2 = set(dataframes[table2_name][col2].dropna().unique())\n",
    "                                    overlap = vals1 & vals2\n",
    "                                    if len(overlap) > 0 and len(vals1) <= len(vals2):\n",
    "                                        relationships[table1_name].append({\n",
    "                                            'foreign_key': col1,\n",
    "                                            'references': table2_name,\n",
    "                                            'referenced_column': col2,\n",
    "                                            'overlap_count': len(overlap)\n",
    "                                        })\n",
    "                                except (TypeError, ValueError):\n",
    "                                    continue\n",
    "\n",
    "# Build Mermaid ERD syntax\n",
    "mermaid_code = \"erDiagram\\n\"\n",
    "\n",
    "# Add entities (tables)\n",
    "for table_name, info in schema_info.items():\n",
    "    table_name_clean = sanitize_name(table_name)\n",
    "    pk = info['unique_cols'][0] if info['unique_cols'] else info['id_cols'][0] if info['id_cols'] else None\n",
    "    \n",
    "    # Get visible columns (exclude nested)\n",
    "    visible_cols = [c for c in info['columns'] if c not in [nc[0] for nc in info['nested_cols']]]\n",
    "    \n",
    "    # Add table definition with key columns\n",
    "    mermaid_code += f\"    {table_name_clean} {{\\n\"\n",
    "    \n",
    "    # Show primary key first\n",
    "    if pk and pk in visible_cols:\n",
    "        pk_clean = sanitize_column_name(pk)\n",
    "        mermaid_code += f\"        {pk_clean} string PK\\n\"\n",
    "    \n",
    "    # Show other key columns\n",
    "    key_cols = [c for c in visible_cols if any(x in c.lower() for x in ['id', 'name', 'type', 'status', 'ip', 'mac'])]\n",
    "    df = dataframes[table_name]\n",
    "    \n",
    "    for col in key_cols[:8]:  # Limit columns shown\n",
    "        if col == pk:\n",
    "            continue\n",
    "        # Determine type from pandas dtype\n",
    "        if col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "            col_type = \"number\"\n",
    "        elif 'time' in col.lower() or 'date' in col.lower():\n",
    "            col_type = \"datetime\"\n",
    "        else:\n",
    "            col_type = \"string\"\n",
    "        \n",
    "        col_clean = sanitize_column_name(col)\n",
    "        mermaid_code += f\"        {col_clean} {col_type}\\n\"\n",
    "    \n",
    "    # Add count indicator if more columns exist\n",
    "    remaining = len(visible_cols) - len(key_cols) - (1 if pk else 0)\n",
    "    if remaining > 0:\n",
    "        mermaid_code += f\"        ... {remaining} more columns\\n\"\n",
    "    \n",
    "    mermaid_code += f\"    }}\\n\\n\"\n",
    "\n",
    "# Add relationships\n",
    "for table_name, fks in relationships.items():\n",
    "    for fk in fks:\n",
    "        table1 = sanitize_name(table_name)\n",
    "        table2 = sanitize_name(fk['references'])\n",
    "        fk_name = sanitize_column_name(fk['foreign_key'])\n",
    "        # Many-to-one relationship (FK implies many on the FK side)\n",
    "        mermaid_code += f\"    {table1} ||--o{{ {table2} : \\\"{fk_name}\\\"\\n\"\n",
    "\n",
    "# Display Mermaid diagram\n",
    "display(Markdown(f\"\"\"```mermaid\n",
    "{mermaid_code}\n",
    "```\"\"\"))\n",
    "\n",
    "print(f\"\\n‚úì ERD Generated ({len(schema_info)} tables, {sum(len(v) for v in relationships.values())} relationships)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Export Mermaid Code\n",
    "\n",
    "Export the Mermaid ERD code to a file for use in other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mermaid ERD saved to: unifi_erd.mmd\n",
      "   You can view this at: https://mermaid.live/\n",
      "   Or use in GitHub/GitLab markdown, Obsidian, or other Mermaid-compatible tools\n",
      "\n",
      "Preview (first 500 chars):\n",
      "============================================================\n",
      "erDiagram\n",
      "    hosts {\n",
      "        id string PK\n",
      "        hardwareId string\n",
      "        type string\n",
      "        ipAddress string\n",
      "        userData.status string\n",
      "        reportedState.controller_uuid string\n",
      "        reportedState.hardware_id string\n",
      "        reportedState.host_type number\n",
      "        ... 85 more columns\n",
      "    }\n",
      "\n",
      "    sites {\n",
      "        siteId string PK\n",
      "        hostId string\n",
      "        meta.name string\n",
      "        statistics.counts.offlineWifiDevice number\n",
      "        statistics.counts.wifiDevice number\n",
      "        meta.gat...\n"
     ]
    }
   ],
   "source": [
    "# Export Mermaid code to file (reuse code from above if it exists)\n",
    "if 'mermaid_code' in globals():\n",
    "    mermaid_file = \"unifi_erd.mmd\"\n",
    "    with open(mermaid_file, 'w') as f:\n",
    "        f.write(mermaid_code)\n",
    "    \n",
    "    print(f\"‚úì Mermaid ERD saved to: {mermaid_file}\")\n",
    "    print(f\"   You can view this at: https://mermaid.live/\")\n",
    "    print(f\"   Or use in GitHub/GitLab markdown, Obsidian, or other Mermaid-compatible tools\")\n",
    "    print(f\"\\nPreview (first 500 chars):\")\n",
    "    print(\"=\"*60)\n",
    "    print(mermaid_code[:500] + \"...\" if len(mermaid_code) > 500 else mermaid_code)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Run the ERD generation cell above first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging: Launch Notebook in Browser\n",
    "\n",
    "**For better visualization and debugging**, launch this notebook in a browser with Playwright automation hooks. The IDE's notebook viewer is horrible for visualizations - this gives you full browser debugging capabilities!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch this notebook in browser for better visualization & debugging\n",
    "from playwright.sync_api import sync_playwright\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_file = Path(\"unifi_data_analysis.ipynb\")\n",
    "notebook_name = notebook_file.name\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LAUNCHING NOTEBOOK IN BROWSER FOR DEBUGGING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for Jupyter server\n",
    "jupyter_url = None\n",
    "try:\n",
    "    import requests\n",
    "    for port in [8888, 8889, 8890]:\n",
    "        try:\n",
    "            response = requests.get(f'http://localhost:{port}', timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                jupyter_url = f\"http://localhost:{port}\"\n",
    "                print(f\"‚úì Jupyter server running on {jupyter_url}\")\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not jupyter_url:\n",
    "    print(\"\\nüöÄ Starting Jupyter server...\")\n",
    "    jupyter_cmd = [sys.executable, '-m', 'jupyter', 'notebook', '--no-browser', '--port=8888']\n",
    "    subprocess.Popen(jupyter_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(\"   Waiting for server...\")\n",
    "    for i in range(15):\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            import requests\n",
    "            response = requests.get('http://localhost:8888', timeout=1)\n",
    "            if response.status_code == 200:\n",
    "                jupyter_url = \"http://localhost:8888\"\n",
    "                print(f\"‚úì Server started on {jupyter_url}\")\n",
    "                break\n",
    "        except:\n",
    "            if i % 3 == 0:\n",
    "                print(f\"   Still waiting... ({i+1}/15)\")\n",
    "    if not jupyter_url:\n",
    "        jupyter_url = \"http://localhost:8888\"\n",
    "        time.sleep(2)\n",
    "\n",
    "if jupyter_url:\n",
    "    notebook_url = f\"{jupyter_url}/notebooks/{notebook_name}\"\n",
    "    print(f\"\\nüåê Launching with Playwright browser automation...\")\n",
    "    print(f\"   URL: {notebook_url}\\n\")\n",
    "    \n",
    "    try:\n",
    "        with sync_playwright() as p:\n",
    "            print(\"üöÄ Launching browser with automation hooks...\")\n",
    "            browser = p.chromium.launch(headless=False, args=['--start-maximized'])\n",
    "            context = browser.new_context(viewport={'width': 1920, 'height': 1080})\n",
    "            page = context.new_page()\n",
    "            \n",
    "            print(\"üìì Loading notebook...\")\n",
    "            page.goto(notebook_url, wait_until='networkidle', timeout=30000)\n",
    "            \n",
    "            print(\"‚úì Notebook opened in browser!\")\n",
    "            print(\"\\n‚úÖ Browser window open - you can:\")\n",
    "            print(\"   üìä View all visualizations clearly\")\n",
    "            print(\"   üêõ Debug with browser developer tools\")\n",
    "            print(\"   üéØ Step through cells interactively\")\n",
    "            print(\"   üîß Use Playwright hooks for automation\")\n",
    "            print(f\"\\nüìù Server: {jupyter_url}\")\n",
    "            print(\"üí° Close browser window when done\")\n",
    "            print(\"\\n‚è∏Ô∏è  This is your debugging meta-document!\\n\")\n",
    "            \n",
    "            try:\n",
    "                while browser.connected:\n",
    "                    time.sleep(1)\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n‚ö†Ô∏è  Closing browser...\")\n",
    "            \n",
    "            if browser.connected:\n",
    "                browser.close()\n",
    "            print(\"‚úì Browser closed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error: {e}\")\n",
    "        import webbrowser\n",
    "        webbrowser.open(notebook_url)\n",
    "        print(\"‚úì Opened in default browser\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
